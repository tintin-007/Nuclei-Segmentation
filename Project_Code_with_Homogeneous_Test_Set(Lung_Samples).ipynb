{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "#seed = 7\n",
    "#np.random.seed(seed)\n",
    "#####################################\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "#####################################\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce binary masks for training, resize all the masks to 500X500 \n",
    "def Label_to_BinLabel(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #print(img.shape)\n",
    "        #cv2.imwrite(source+str(j)+'.png', thresh)#final mask\n",
    "        #img4 = cv2.imread(source+str(j)+'.png')\n",
    "        img4 = cv2.resize(img,(500, 500))\n",
    "        ret,thresh = cv2.threshold(img4,0,255,cv2.THRESH_BINARY)\n",
    "        print(thresh)\n",
    "        print(thresh.shape)\n",
    "        print('_'*40)\n",
    "        cv2.imwrite(\"/home/hp/data/Train/label1/%d.png\"%(j),thresh)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0 255 255 ... 255 255 255]\n",
      " [  0 255 255 ... 255 255 255]\n",
      " [  0 255 255 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255   0]\n",
      " [  0   0   0 ... 255 255   0]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " ...\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0 255]\n",
      " [  0   0   0 ...   0 255 255]\n",
      " [  0   0   0 ...   0 255 255]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Train/label') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Label_to_BinLabel('/home/hp/data/Train/label/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize all of 23 train images to 500X500\n",
    "def Resize_images(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')        \n",
    "        img = cv2.resize(img,(500, 500))\n",
    "        print(img)\n",
    "        print(img.shape)\n",
    "        cv2.imwrite(\"/home/hp/data/Train/image1/%d.png\"%(j),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[[[185 165 211]\n",
      "  [205 197 234]\n",
      "  [211 195 236]\n",
      "  ...\n",
      "  [178 150 212]\n",
      "  [178 147 216]\n",
      "  [167 136 203]]\n",
      "\n",
      " [[182 160 204]\n",
      "  [191 178 210]\n",
      "  [209 190 228]\n",
      "  ...\n",
      "  [174 146 210]\n",
      "  [172 140 210]\n",
      "  [159 127 194]]\n",
      "\n",
      " [[180 155 197]\n",
      "  [182 162 193]\n",
      "  [202 176 212]\n",
      "  ...\n",
      "  [169 138 202]\n",
      "  [174 140 208]\n",
      "  [181 147 214]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[236 218 241]\n",
      "  [218 200 223]\n",
      "  [199 181 204]\n",
      "  ...\n",
      "  [233 215 238]\n",
      "  [251 231 248]\n",
      "  [230 202 244]]\n",
      "\n",
      " [[242 224 247]\n",
      "  [228 210 233]\n",
      "  [212 193 215]\n",
      "  ...\n",
      "  [251 246 235]\n",
      "  [241 228 229]\n",
      "  [199 171 218]]\n",
      "\n",
      " [[242 226 249]\n",
      "  [229 210 231]\n",
      "  [218 197 218]\n",
      "  ...\n",
      "  [243 233 235]\n",
      "  [210 190 212]\n",
      "  [174 145 199]]]\n",
      "(500, 500, 3)\n",
      "[[[171 126 193]\n",
      "  [155 117 195]\n",
      "  [148 107 191]\n",
      "  ...\n",
      "  [157 111 184]\n",
      "  [159 114 183]\n",
      "  [169 125 191]]\n",
      "\n",
      " [[166 123 187]\n",
      "  [153 115 183]\n",
      "  [150 110 190]\n",
      "  ...\n",
      "  [162 119 191]\n",
      "  [164 121 192]\n",
      "  [174 134 202]]\n",
      "\n",
      " [[156 100 176]\n",
      "  [151 102 183]\n",
      "  [156 111 198]\n",
      "  ...\n",
      "  [169 132 204]\n",
      "  [170 132 208]\n",
      "  [177 144 217]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[202 151 205]\n",
      "  [203 152 197]\n",
      "  [192 137 177]\n",
      "  ...\n",
      "  [176 131 215]\n",
      "  [171 130 199]\n",
      "  [159 111 147]]\n",
      "\n",
      " [[179 129 189]\n",
      "  [173 122 188]\n",
      "  [153 110 174]\n",
      "  ...\n",
      "  [176 134 212]\n",
      "  [179 134 205]\n",
      "  [170 121 174]]\n",
      "\n",
      " [[156 102 161]\n",
      "  [147  94 160]\n",
      "  [131  91 158]\n",
      "  ...\n",
      "  [176 128 198]\n",
      "  [179 130 200]\n",
      "  [174 125 206]]]\n",
      "(500, 500, 3)\n",
      "[[[126  67 109]\n",
      "  [130  68 105]\n",
      "  [137  73 111]\n",
      "  ...\n",
      "  [184 144 225]\n",
      "  [181 143 228]\n",
      "  [176 136 212]]\n",
      "\n",
      " [[131  66 105]\n",
      "  [135  69 103]\n",
      "  [145  80 117]\n",
      "  ...\n",
      "  [185 143 221]\n",
      "  [178 140 221]\n",
      "  [170 132 198]]\n",
      "\n",
      " [[142  79 117]\n",
      "  [149  86 120]\n",
      "  [158  99 137]\n",
      "  ...\n",
      "  [178 137 211]\n",
      "  [169 133 218]\n",
      "  [163 130 203]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[193 167 227]\n",
      "  [195 164 232]\n",
      "  [195 159 223]\n",
      "  ...\n",
      "  [165 123 212]\n",
      "  [162 126 214]\n",
      "  [160 124 210]]\n",
      "\n",
      " [[189 153 210]\n",
      "  [193 162 230]\n",
      "  [194 156 224]\n",
      "  ...\n",
      "  [165 121 208]\n",
      "  [162 124 215]\n",
      "  [158 123 214]]\n",
      "\n",
      " [[179 134 191]\n",
      "  [182 148 204]\n",
      "  [183 144 205]\n",
      "  ...\n",
      "  [165 120 205]\n",
      "  [162 125 215]\n",
      "  [161 125 217]]]\n",
      "(500, 500, 3)\n",
      "[[[169 116 192]\n",
      "  [164 122 192]\n",
      "  [177 148 204]\n",
      "  ...\n",
      "  [186 149 209]\n",
      "  [164 115 168]\n",
      "  [137  91 147]]\n",
      "\n",
      " [[173 126 208]\n",
      "  [169 127 204]\n",
      "  [179 147 211]\n",
      "  ...\n",
      "  [167 130 201]\n",
      "  [144 105 173]\n",
      "  [122  87 151]]\n",
      "\n",
      " [[173 136 214]\n",
      "  [171 133 209]\n",
      "  [178 143 216]\n",
      "  ...\n",
      "  [159 118 190]\n",
      "  [139 103 170]\n",
      "  [128  92 150]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[187 125 178]\n",
      "  [181 111 156]\n",
      "  [191 135 176]\n",
      "  ...\n",
      "  [174 126 165]\n",
      "  [169  98 125]\n",
      "  [154  88 130]]\n",
      "\n",
      " [[145  90 171]\n",
      "  [142  69 138]\n",
      "  [166 102 159]\n",
      "  ...\n",
      "  [172 117 159]\n",
      "  [169  96 130]\n",
      "  [157  90 133]]\n",
      "\n",
      " [[128  93 189]\n",
      "  [125  72 163]\n",
      "  [154 101 185]\n",
      "  ...\n",
      "  [167 119 155]\n",
      "  [158  91 115]\n",
      "  [152  82 100]]]\n",
      "(500, 500, 3)\n",
      "[[[172 151 221]\n",
      "  [179 144 206]\n",
      "  [179 134 204]\n",
      "  ...\n",
      "  [117  61 123]\n",
      "  [120  65 117]\n",
      "  [126  62 131]]\n",
      "\n",
      " [[173 139 214]\n",
      "  [171 123 193]\n",
      "  [169 116 190]\n",
      "  ...\n",
      "  [122  63 123]\n",
      "  [119  60 124]\n",
      "  [115  58 144]]\n",
      "\n",
      " [[170 110 190]\n",
      "  [165 104 180]\n",
      "  [161 111 189]\n",
      "  ...\n",
      "  [122  62 129]\n",
      "  [121  60 127]\n",
      "  [117  68 153]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[155 119 187]\n",
      "  [154 114 179]\n",
      "  [152 109 184]\n",
      "  ...\n",
      "  [141  97 171]\n",
      "  [140  90 163]\n",
      "  [131  87 169]]\n",
      "\n",
      " [[139  98 179]\n",
      "  [144  99 183]\n",
      "  [144  97 179]\n",
      "  ...\n",
      "  [153  98 174]\n",
      "  [148  87 169]\n",
      "  [136  95 173]]\n",
      "\n",
      " [[122  71 154]\n",
      "  [124  76 161]\n",
      "  [127  83 161]\n",
      "  ...\n",
      "  [165 115 213]\n",
      "  [170  96 194]\n",
      "  [154 111 189]]]\n",
      "(500, 500, 3)\n",
      "[[[163 120 185]\n",
      "  [158 120 183]\n",
      "  [153 120 183]\n",
      "  ...\n",
      "  [101  46  79]\n",
      "  [113  65 108]\n",
      "  [136  93 148]]\n",
      "\n",
      " [[169 121 181]\n",
      "  [165 121 180]\n",
      "  [161 121 179]\n",
      "  ...\n",
      "  [ 94  42  76]\n",
      "  [109  61 107]\n",
      "  [132  88 147]]\n",
      "\n",
      " [[173 124 185]\n",
      "  [172 124 183]\n",
      "  [169 124 183]\n",
      "  ...\n",
      "  [ 92  43  78]\n",
      "  [103  56 105]\n",
      "  [118  73 136]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[221 199 215]\n",
      "  [217 195 216]\n",
      "  [206 175 215]\n",
      "  ...\n",
      "  [148  99 161]\n",
      "  [150  98 160]\n",
      "  [152 103 173]]\n",
      "\n",
      " [[219 196 210]\n",
      "  [212 186 211]\n",
      "  [206 166 213]\n",
      "  ...\n",
      "  [154 107 177]\n",
      "  [154 106 174]\n",
      "  [152 104 169]]\n",
      "\n",
      " [[217 197 214]\n",
      "  [209 183 211]\n",
      "  [203 161 207]\n",
      "  ...\n",
      "  [153 120 179]\n",
      "  [151 111 172]\n",
      "  [150 101 165]]]\n",
      "(500, 500, 3)\n",
      "[[[199 177 196]\n",
      "  [200 179 198]\n",
      "  [208 189 206]\n",
      "  ...\n",
      "  [143  90 121]\n",
      "  [136  81 118]\n",
      "  [129  73 113]]\n",
      "\n",
      " [[200 182 199]\n",
      "  [204 188 204]\n",
      "  [216 201 215]\n",
      "  ...\n",
      "  [145  83 126]\n",
      "  [139  78 121]\n",
      "  [140  79 121]]\n",
      "\n",
      " [[201 185 202]\n",
      "  [207 192 208]\n",
      "  [220 207 221]\n",
      "  ...\n",
      "  [137  73 122]\n",
      "  [125  62 109]\n",
      "  [132  69 115]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[187 152 166]\n",
      "  [176 142 156]\n",
      "  [168 137 150]\n",
      "  ...\n",
      "  [125  88 190]\n",
      "  [127  91 190]\n",
      "  [129  94 191]]\n",
      "\n",
      " [[180 142 165]\n",
      "  [173 136 159]\n",
      "  [168 134 158]\n",
      "  ...\n",
      "  [126  90 187]\n",
      "  [124  89 182]\n",
      "  [126  91 183]]\n",
      "\n",
      " [[177 141 165]\n",
      "  [178 141 166]\n",
      "  [178 141 168]\n",
      "  ...\n",
      "  [132  95 189]\n",
      "  [131  95 185]\n",
      "  [132  97 184]]]\n",
      "(500, 500, 3)\n",
      "[[[165 126 175]\n",
      "  [156 119 166]\n",
      "  [151 117 162]\n",
      "  ...\n",
      "  [173 130 167]\n",
      "  [178 138 173]\n",
      "  [196 158 193]]\n",
      "\n",
      " [[172 128 181]\n",
      "  [162 117 169]\n",
      "  [158 112 162]\n",
      "  ...\n",
      "  [168 122 161]\n",
      "  [170 125 163]\n",
      "  [188 145 182]]\n",
      "\n",
      " [[166 118 168]\n",
      "  [156 107 156]\n",
      "  [153 101 149]\n",
      "  ...\n",
      "  [167 119 160]\n",
      "  [164 117 157]\n",
      "  [177 130 170]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[174 137 174]\n",
      "  [184 150 186]\n",
      "  [190 163 198]\n",
      "  ...\n",
      "  [204 192 211]\n",
      "  [210 195 215]\n",
      "  [202 187 206]]\n",
      "\n",
      " [[181 136 175]\n",
      "  [192 149 187]\n",
      "  [193 158 193]\n",
      "  ...\n",
      "  [209 196 214]\n",
      "  [212 199 216]\n",
      "  [203 190 207]]\n",
      "\n",
      " [[176 129 168]\n",
      "  [186 141 179]\n",
      "  [188 150 186]\n",
      "  ...\n",
      "  [207 194 210]\n",
      "  [210 194 210]\n",
      "  [206 189 205]]]\n",
      "(500, 500, 3)\n",
      "[[[220 209 250]\n",
      "  [200 182 240]\n",
      "  [179 138 196]\n",
      "  ...\n",
      "  [134  78 134]\n",
      "  [132  87 140]\n",
      "  [127  75 115]]\n",
      "\n",
      " [[212 187 239]\n",
      "  [182 145 218]\n",
      "  [156 102 168]\n",
      "  ...\n",
      "  [132  77 141]\n",
      "  [129  81 136]\n",
      "  [124  66 104]]\n",
      "\n",
      " [[203 161 220]\n",
      "  [173 116 184]\n",
      "  [149  83 145]\n",
      "  ...\n",
      "  [137  74 144]\n",
      "  [133  74 137]\n",
      "  [128  56 103]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[172 120 209]\n",
      "  [164 107 205]\n",
      "  [161 106 212]\n",
      "  ...\n",
      "  [246 242 241]\n",
      "  [246 239 242]\n",
      "  [246 237 243]]\n",
      "\n",
      " [[174 117 211]\n",
      "  [159  95 191]\n",
      "  [150  87 186]\n",
      "  ...\n",
      "  [244 241 244]\n",
      "  [243 236 243]\n",
      "  [244 235 243]]\n",
      "\n",
      " [[176 124 223]\n",
      "  [156  92 186]\n",
      "  [142  75 165]\n",
      "  ...\n",
      "  [239 237 249]\n",
      "  [236 231 247]\n",
      "  [236 230 245]]]\n",
      "(500, 500, 3)\n",
      "[[[140  72 153]\n",
      "  [133  65 153]\n",
      "  [124  56 149]\n",
      "  ...\n",
      "  [141  65 140]\n",
      "  [144  66 145]\n",
      "  [138  68 165]]\n",
      "\n",
      " [[151  90 183]\n",
      "  [142  77 169]\n",
      "  [129  61 153]\n",
      "  ...\n",
      "  [142  66 140]\n",
      "  [146  68 147]\n",
      "  [143  77 163]]\n",
      "\n",
      " [[151  96 195]\n",
      "  [141  81 170]\n",
      "  [129  65 146]\n",
      "  ...\n",
      "  [141  72 155]\n",
      "  [145  75 166]\n",
      "  [148  95 182]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[196 158 191]\n",
      "  [194 155 193]\n",
      "  [194 154 196]\n",
      "  ...\n",
      "  [136  77 179]\n",
      "  [136  81 193]\n",
      "  [144 102 212]]\n",
      "\n",
      " [[198 161 196]\n",
      "  [195 158 198]\n",
      "  [193 156 203]\n",
      "  ...\n",
      "  [137  75 174]\n",
      "  [137  75 184]\n",
      "  [147 104 207]]\n",
      "\n",
      " [[197 158 193]\n",
      "  [190 150 192]\n",
      "  [185 144 195]\n",
      "  ...\n",
      "  [143  81 182]\n",
      "  [142  77 184]\n",
      "  [148 100 197]]]\n",
      "(500, 500, 3)\n",
      "[[[120  60 151]\n",
      "  [110  68 170]\n",
      "  [112  62 152]\n",
      "  ...\n",
      "  [ 99  31 100]\n",
      "  [102  38  97]\n",
      "  [101  43  97]]\n",
      "\n",
      " [[121  65 178]\n",
      "  [105  60 174]\n",
      "  [112  56 162]\n",
      "  ...\n",
      "  [ 94  30  89]\n",
      "  [ 97  35  82]\n",
      "  [ 97  38  80]]\n",
      "\n",
      " [[124  70 193]\n",
      "  [111  60 175]\n",
      "  [123  60 173]\n",
      "  ...\n",
      "  [ 83  27  73]\n",
      "  [ 87  30  61]\n",
      "  [ 89  31  57]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[148  87 161]\n",
      "  [154  88 174]\n",
      "  [156  91 173]\n",
      "  ...\n",
      "  [184 141 204]\n",
      "  [186 142 203]\n",
      "  [187 140 199]]\n",
      "\n",
      " [[151  89 157]\n",
      "  [165  96 180]\n",
      "  [167  98 177]\n",
      "  ...\n",
      "  [185 159 216]\n",
      "  [188 149 205]\n",
      "  [190 137 191]]\n",
      "\n",
      " [[162 105 160]\n",
      "  [180 115 174]\n",
      "  [182 114 173]\n",
      "  ...\n",
      "  [186 155 216]\n",
      "  [188 144 203]\n",
      "  [192 133 190]]]\n",
      "(500, 500, 3)\n",
      "[[[167 122 183]\n",
      "  [188 144 208]\n",
      "  [180 137 206]\n",
      "  ...\n",
      "  [174 117 172]\n",
      "  [186 131 185]\n",
      "  [168 114 167]]\n",
      "\n",
      " [[181 120 191]\n",
      "  [195 136 209]\n",
      "  [193 137 217]\n",
      "  ...\n",
      "  [158 101 149]\n",
      "  [162 106 156]\n",
      "  [153  96 147]]\n",
      "\n",
      " [[179 111 184]\n",
      "  [189 122 198]\n",
      "  [195 132 215]\n",
      "  ...\n",
      "  [138  82 126]\n",
      "  [142  83 132]\n",
      "  [145  86 136]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[162 105 155]\n",
      "  [168 113 164]\n",
      "  [182 130 184]\n",
      "  ...\n",
      "  [127  63 123]\n",
      "  [121  57 111]\n",
      "  [120  56 108]]\n",
      "\n",
      " [[167 102 167]\n",
      "  [160  97 165]\n",
      "  [166 108 180]\n",
      "  ...\n",
      "  [128  65 122]\n",
      "  [120  63 100]\n",
      "  [116  62  91]]\n",
      "\n",
      " [[174 106 177]\n",
      "  [156  90 163]\n",
      "  [152  90 168]\n",
      "  ...\n",
      "  [141  76 138]\n",
      "  [119  62 100]\n",
      "  [112  59  87]]]\n",
      "(500, 500, 3)\n",
      "[[[175 140 180]\n",
      "  [165 130 170]\n",
      "  [154 113 164]\n",
      "  ...\n",
      "  [211 187 235]\n",
      "  [197 174 228]\n",
      "  [169 146 200]]\n",
      "\n",
      " [[177 141 183]\n",
      "  [156 120 162]\n",
      "  [154 111 162]\n",
      "  ...\n",
      "  [205 176 232]\n",
      "  [188 160 220]\n",
      "  [159 131 191]]\n",
      "\n",
      " [[180 141 186]\n",
      "  [151 112 157]\n",
      "  [152 110 158]\n",
      "  ...\n",
      "  [196 161 225]\n",
      "  [179 145 209]\n",
      "  [154 120 184]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[163 123 178]\n",
      "  [160 120 175]\n",
      "  [156 114 169]\n",
      "  ...\n",
      "  [192 163 209]\n",
      "  [202 167 224]\n",
      "  [191 156 213]]\n",
      "\n",
      " [[171 132 188]\n",
      "  [164 125 181]\n",
      "  [161 116 172]\n",
      "  ...\n",
      "  [199 173 226]\n",
      "  [211 178 245]\n",
      "  [191 158 225]]\n",
      "\n",
      " [[186 149 205]\n",
      "  [168 131 187]\n",
      "  [170 122 180]\n",
      "  ...\n",
      "  [215 192 247]\n",
      "  [198 169 242]\n",
      "  [166 137 210]]]\n",
      "(500, 500, 3)\n",
      "[[[162 124 199]\n",
      "  [169 130 205]\n",
      "  [177 137 211]\n",
      "  ...\n",
      "  [205 177 237]\n",
      "  [192 165 212]\n",
      "  [183 141 227]]\n",
      "\n",
      " [[174 139 213]\n",
      "  [183 145 221]\n",
      "  [169 129 206]\n",
      "  ...\n",
      "  [194 158 226]\n",
      "  [194 159 222]\n",
      "  [174 134 210]]\n",
      "\n",
      " [[184 153 222]\n",
      "  [191 156 232]\n",
      "  [184 146 225]\n",
      "  ...\n",
      "  [183 140 219]\n",
      "  [196 154 232]\n",
      "  [178 139 208]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[120  77 156]\n",
      "  [136  88 173]\n",
      "  [154 102 188]\n",
      "  ...\n",
      "  [128  84 143]\n",
      "  [176 118 185]\n",
      "  [161 127 186]]\n",
      "\n",
      " [[125  76 133]\n",
      "  [140  83 145]\n",
      "  [162 102 167]\n",
      "  ...\n",
      "  [122  77 141]\n",
      "  [164 112 196]\n",
      "  [155 113 181]]\n",
      "\n",
      " [[149 101 161]\n",
      "  [152 113 169]\n",
      "  [149 114 167]\n",
      "  ...\n",
      "  [111  67 126]\n",
      "  [132  84 164]\n",
      "  [140  93 174]]]\n",
      "(500, 500, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[136  79 130]\n",
      "  [134  78 127]\n",
      "  [133  77 126]\n",
      "  ...\n",
      "  [177 143 208]\n",
      "  [194 160 225]\n",
      "  [193 159 224]]\n",
      "\n",
      " [[136  78 132]\n",
      "  [132  76 127]\n",
      "  [130  74 123]\n",
      "  ...\n",
      "  [173 139 204]\n",
      "  [184 149 216]\n",
      "  [185 151 216]]\n",
      "\n",
      " [[134  77 132]\n",
      "  [129  75 128]\n",
      "  [128  72 123]\n",
      "  ...\n",
      "  [160 125 192]\n",
      "  [163 127 197]\n",
      "  [170 135 202]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[142 103 188]\n",
      "  [129  91 173]\n",
      "  [138  98 180]\n",
      "  ...\n",
      "  [180 152 221]\n",
      "  [180 149 218]\n",
      "  [184 153 220]]\n",
      "\n",
      " [[141 103 185]\n",
      "  [135  97 179]\n",
      "  [153 114 194]\n",
      "  ...\n",
      "  [176 148 217]\n",
      "  [179 148 217]\n",
      "  [186 155 222]]\n",
      "\n",
      " [[147 109 191]\n",
      "  [147 110 190]\n",
      "  [169 130 210]\n",
      "  ...\n",
      "  [169 141 210]\n",
      "  [175 144 213]\n",
      "  [184 153 220]]]\n",
      "(500, 500, 3)\n",
      "[[[137  74 166]\n",
      "  [151  89 179]\n",
      "  [170 106 196]\n",
      "  ...\n",
      "  [143  91 145]\n",
      "  [144  92 146]\n",
      "  [147  95 149]]\n",
      "\n",
      " [[136  73 165]\n",
      "  [145  82 174]\n",
      "  [156  94 184]\n",
      "  ...\n",
      "  [134  82 136]\n",
      "  [137  82 137]\n",
      "  [138  86 140]]\n",
      "\n",
      " [[139  77 171]\n",
      "  [141  80 171]\n",
      "  [145  84 174]\n",
      "  ...\n",
      "  [134  79 136]\n",
      "  [137  79 137]\n",
      "  [138  83 140]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[120  55 100]\n",
      "  [126  61 106]\n",
      "  [136  73 115]\n",
      "  ...\n",
      "  [179 140 202]\n",
      "  [184 144 209]\n",
      "  [188 149 211]]\n",
      "\n",
      " [[109  44  89]\n",
      "  [109  44  89]\n",
      "  [110  47  89]\n",
      "  ...\n",
      "  [182 142 207]\n",
      "  [182 141 208]\n",
      "  [182 142 207]]\n",
      "\n",
      " [[102  37  82]\n",
      "  [ 98  33  78]\n",
      "  [ 94  31  73]\n",
      "  ...\n",
      "  [179 138 205]\n",
      "  [176 135 202]\n",
      "  [172 131 198]]]\n",
      "(500, 500, 3)\n",
      "[[[169 155 189]\n",
      "  [223 209 243]\n",
      "  [232 213 252]\n",
      "  ...\n",
      "  [149 118 179]\n",
      "  [160 136 190]\n",
      "  [181 157 211]]\n",
      "\n",
      " [[164 139 183]\n",
      "  [210 185 229]\n",
      "  [208 184 226]\n",
      "  ...\n",
      "  [153 122 191]\n",
      "  [186 168 209]\n",
      "  [214 196 237]]\n",
      "\n",
      " [[162 126 180]\n",
      "  [195 159 213]\n",
      "  [180 151 196]\n",
      "  ...\n",
      "  [166 131 211]\n",
      "  [214 200 228]\n",
      "  [242 228 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[157  99 180]\n",
      "  [155  97 178]\n",
      "  [161 119 196]\n",
      "  ...\n",
      "  [194 166 225]\n",
      "  [185 158 222]\n",
      "  [188 161 225]]\n",
      "\n",
      " [[162 107 192]\n",
      "  [144  89 174]\n",
      "  [158 112 189]\n",
      "  ...\n",
      "  [181 148 215]\n",
      "  [194 165 234]\n",
      "  [204 175 244]]\n",
      "\n",
      " [[153  97 186]\n",
      "  [138  82 171]\n",
      "  [141 109 186]\n",
      "  ...\n",
      "  [162 124 200]\n",
      "  [193 164 237]\n",
      "  [210 181 254]]]\n",
      "(500, 500, 3)\n",
      "[[[192 141 222]\n",
      "  [185 133 215]\n",
      "  [179 124 206]\n",
      "  ...\n",
      "  [165 117 186]\n",
      "  [160 107 185]\n",
      "  [166 111 191]]\n",
      "\n",
      " [[181 120 198]\n",
      "  [188 121 200]\n",
      "  [186 116 197]\n",
      "  ...\n",
      "  [151  98 180]\n",
      "  [168 109 185]\n",
      "  [185 127 196]]\n",
      "\n",
      " [[172 105 181]\n",
      "  [187 113 189]\n",
      "  [190 114 193]\n",
      "  ...\n",
      "  [151  92 180]\n",
      "  [172 107 182]\n",
      "  [189 125 193]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[201 153 229]\n",
      "  [208 155 237]\n",
      "  [197 140 225]\n",
      "  ...\n",
      "  [169 111 169]\n",
      "  [169 116 193]\n",
      "  [183 132 219]]\n",
      "\n",
      " [[187 131 201]\n",
      "  [198 137 214]\n",
      "  [191 126 209]\n",
      "  ...\n",
      "  [159  97 160]\n",
      "  [173 118 196]\n",
      "  [192 142 226]]\n",
      "\n",
      " [[164 103 173]\n",
      "  [183 117 192]\n",
      "  [194 127 204]\n",
      "  ...\n",
      "  [163 101 168]\n",
      "  [171 110 186]\n",
      "  [186 128 206]]]\n",
      "(500, 500, 3)\n",
      "[[[137  65 188]\n",
      "  [141  67 194]\n",
      "  [146  71 192]\n",
      "  ...\n",
      "  [135  63 136]\n",
      "  [135  60 136]\n",
      "  [134  63 139]]\n",
      "\n",
      " [[137  68 200]\n",
      "  [139  72 201]\n",
      "  [141  77 195]\n",
      "  ...\n",
      "  [132  64 139]\n",
      "  [132  61 137]\n",
      "  [131  64 139]]\n",
      "\n",
      " [[140  74 204]\n",
      "  [142  78 206]\n",
      "  [144  80 200]\n",
      "  ...\n",
      "  [121  59 130]\n",
      "  [123  59 132]\n",
      "  [125  61 135]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[166 115 200]\n",
      "  [167 112 190]\n",
      "  [151  91 157]\n",
      "  ...\n",
      "  [ 95  30  72]\n",
      "  [ 99  30  75]\n",
      "  [105  32  82]]\n",
      "\n",
      " [[164 114 196]\n",
      "  [165 107 182]\n",
      "  [148  83 146]\n",
      "  ...\n",
      "  [ 95  26  73]\n",
      "  [ 97  27  75]\n",
      "  [100  30  80]]\n",
      "\n",
      " [[178 126 206]\n",
      "  [175 116 190]\n",
      "  [152  87 150]\n",
      "  ...\n",
      "  [ 93  24  76]\n",
      "  [ 93  25  75]\n",
      "  [ 93  27  77]]]\n",
      "(500, 500, 3)\n",
      "[[[195 172 237]\n",
      "  [182 167 248]\n",
      "  [169 152 248]\n",
      "  ...\n",
      "  [119  53  94]\n",
      "  [ 97  48  94]\n",
      "  [ 97  51 104]]\n",
      "\n",
      " [[208 181 226]\n",
      "  [183 155 221]\n",
      "  [165 129 219]\n",
      "  ...\n",
      "  [174 123 184]\n",
      "  [161 108 181]\n",
      "  [149 103 176]]\n",
      "\n",
      " [[209 162 211]\n",
      "  [186 140 207]\n",
      "  [163 120 207]\n",
      "  ...\n",
      "  [188 163 226]\n",
      "  [186 159 224]\n",
      "  [180 155 219]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[158 135 227]\n",
      "  [168 150 238]\n",
      "  [175 154 237]\n",
      "  ...\n",
      "  [ 81  50 109]\n",
      "  [101  64 133]\n",
      "  [127  79 175]]\n",
      "\n",
      " [[151 122 222]\n",
      "  [157 135 233]\n",
      "  [165 142 232]\n",
      "  ...\n",
      "  [ 77  50 104]\n",
      "  [ 93  63 126]\n",
      "  [124  82 168]]\n",
      "\n",
      " [[145 107 212]\n",
      "  [147 118 217]\n",
      "  [152 126 212]\n",
      "  ...\n",
      "  [ 86  52 103]\n",
      "  [100  68 121]\n",
      "  [129  88 156]]]\n",
      "(500, 500, 3)\n",
      "[[[205 169 190]\n",
      "  [214 203 219]\n",
      "  [218 205 238]\n",
      "  ...\n",
      "  [135  86 120]\n",
      "  [145  94 119]\n",
      "  [159  90 137]]\n",
      "\n",
      " [[222 159 195]\n",
      "  [231 212 220]\n",
      "  [231 231 234]\n",
      "  ...\n",
      "  [115  71 109]\n",
      "  [122  77 103]\n",
      "  [125  75 105]]\n",
      "\n",
      " [[198 153 167]\n",
      "  [226 181 201]\n",
      "  [247 217 245]\n",
      "  ...\n",
      "  [132  76 117]\n",
      "  [132  74 114]\n",
      "  [114  63 102]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175 158 187]\n",
      "  [158 139 168]\n",
      "  [153 116 148]\n",
      "  ...\n",
      "  [187 130 150]\n",
      "  [186 154 171]\n",
      "  [167 129 167]]\n",
      "\n",
      " [[167 137 176]\n",
      "  [170 133 161]\n",
      "  [176 141 160]\n",
      "  ...\n",
      "  [170 123 137]\n",
      "  [179 131 141]\n",
      "  [192 124 172]]\n",
      "\n",
      " [[171 137 170]\n",
      "  [173 129 160]\n",
      "  [177 133 168]\n",
      "  ...\n",
      "  [151  98 116]\n",
      "  [157 103 121]\n",
      "  [178 122 156]]]\n",
      "(500, 500, 3)\n",
      "[[[103  67 168]\n",
      "  [108  79 183]\n",
      "  [118  83 188]\n",
      "  ...\n",
      "  [ 91  33  81]\n",
      "  [ 98  34  85]\n",
      "  [100  44 109]]\n",
      "\n",
      " [[119  72 171]\n",
      "  [117  83 190]\n",
      "  [115  78 189]\n",
      "  ...\n",
      "  [ 96  32  81]\n",
      "  [104  35  83]\n",
      "  [109  50 107]]\n",
      "\n",
      " [[133  86 185]\n",
      "  [128  80 192]\n",
      "  [119  70 190]\n",
      "  ...\n",
      "  [ 98  36  91]\n",
      "  [102  42  88]\n",
      "  [114  61 108]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[122  71 144]\n",
      "  [144  99 190]\n",
      "  [184 151 237]\n",
      "  ...\n",
      "  [151 117 196]\n",
      "  [156 122 196]\n",
      "  [164 120 194]]\n",
      "\n",
      " [[116  61 142]\n",
      "  [129  79 180]\n",
      "  [159 118 223]\n",
      "  ...\n",
      "  [148 109 187]\n",
      "  [146 109 186]\n",
      "  [147 104 180]]\n",
      "\n",
      " [[108  56 135]\n",
      "  [116  66 164]\n",
      "  [137  93 201]\n",
      "  ...\n",
      "  [145  96 171]\n",
      "  [144  88 164]\n",
      "  [137  79 154]]]\n",
      "(500, 500, 3)\n",
      "[[[107  45  98]\n",
      "  [ 99  40 100]\n",
      "  [ 93  36 102]\n",
      "  ...\n",
      "  [108  57 131]\n",
      "  [117  55 134]\n",
      "  [129  63 164]]\n",
      "\n",
      " [[103  44  95]\n",
      "  [ 93  39  93]\n",
      "  [ 87  34  99]\n",
      "  ...\n",
      "  [109  58 139]\n",
      "  [120  58 140]\n",
      "  [125  61 155]]\n",
      "\n",
      " [[ 97  45  98]\n",
      "  [ 90  41  91]\n",
      "  [ 86  37  97]\n",
      "  ...\n",
      "  [115  64 146]\n",
      "  [122  66 149]\n",
      "  [118  66 157]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 74  34  73]\n",
      "  [ 78  33  79]\n",
      "  [ 81  32  93]\n",
      "  ...\n",
      "  [122  65 135]\n",
      "  [124  73 140]\n",
      "  [121  73 164]]\n",
      "\n",
      " [[ 76  36  70]\n",
      "  [ 80  32  69]\n",
      "  [ 83  27  78]\n",
      "  ...\n",
      "  [132  77 163]\n",
      "  [133  85 160]\n",
      "  [123  75 162]]\n",
      "\n",
      " [[ 79  37  75]\n",
      "  [ 84  29  67]\n",
      "  [ 87  21  72]\n",
      "  ...\n",
      "  [133  86 192]\n",
      "  [132  93 179]\n",
      "  [133  83 167]]]\n",
      "(500, 500, 3)\n",
      "[[[173 113 174]\n",
      "  [178 121 178]\n",
      "  [173 123 190]\n",
      "  ...\n",
      "  [195 154 212]\n",
      "  [176 133 177]\n",
      "  [154 103 132]]\n",
      "\n",
      " [[179 130 186]\n",
      "  [180 118 179]\n",
      "  [173 120 186]\n",
      "  ...\n",
      "  [190 147 196]\n",
      "  [162 114 150]\n",
      "  [130  75  95]]\n",
      "\n",
      " [[181 135 188]\n",
      "  [180 121 178]\n",
      "  [172 118 179]\n",
      "  ...\n",
      "  [180 145 193]\n",
      "  [156 107 142]\n",
      "  [127  67  90]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[151  95 158]\n",
      "  [153 128 191]\n",
      "  [141 112 172]\n",
      "  ...\n",
      "  [ 89  22  58]\n",
      "  [ 90  29  58]\n",
      "  [ 94  36  55]]\n",
      "\n",
      " [[152  93 163]\n",
      "  [152 117 186]\n",
      "  [142 116 173]\n",
      "  ...\n",
      "  [105  38  69]\n",
      "  [ 99  36  57]\n",
      "  [ 97  36  56]]\n",
      "\n",
      " [[153  97 172]\n",
      "  [151 102 174]\n",
      "  [143 113 168]\n",
      "  ...\n",
      "  [126  61  95]\n",
      "  [110  47  66]\n",
      "  [ 99  36  69]]]\n",
      "(500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Train/image') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Resize_images('/home/hp/data/Train/image/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Extracting 5 patches of size 256X256 from each image\n",
    "\n",
    "path = '/home/hp/data/Train/image1/'\n",
    "path1 = '/home/hp/data/Train/label1/'\n",
    "list = os.listdir('/home/hp/data/Train/image1') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "patch_size = (256, 256)\n",
    "\n",
    "k=1\n",
    "for i in range(1, size+1):\n",
    "    img = cv2.imread(path+str(i)+'.png')\n",
    "    img1 = cv2.imread(path1+str(i)+'.png')\n",
    "    data = extract_patches_2d(img, patch_size, max_patches=5,random_state=1)\n",
    "    data1 = extract_patches_2d(img1, patch_size, max_patches=5,random_state=1)\n",
    "    print(data.shape)\n",
    "    print(data1.shape)\n",
    "    data = np.array(data) \n",
    "    data1 = np.array(data1) \n",
    "    print(data.shape)\n",
    "    print(data1.shape)\n",
    "    print('-'*30)\n",
    "    #print(data.shape)\n",
    "    #print(data1.shape)\n",
    "    for j in range(data.shape[0]):\n",
    "        img = data[j]\n",
    "        img1 = data1[j]\n",
    "        img = array_to_img(img)\n",
    "        img1 = array_to_img(img1)\n",
    "        img.save(\"/home/hp/patch_image/%d.png\"%(k))\n",
    "        img1.save(\"/home/hp/patch_label/%d.png\"%(k))\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0.2,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "#augmentation\n",
    "\n",
    "seed = 1\n",
    "\n",
    "path = '/home/hp/patch_image/'\n",
    "path2 = '/home/hp/patch_label/'\n",
    "list = os.listdir('/home/hp/patch_image/') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "for i in range(1, size+1):\n",
    "        img = load_img(path+str(i)+'.png')   \n",
    "        x = img_to_array(img)  \n",
    "        x = x.reshape((1,) + x.shape)  \n",
    "        \n",
    "        img2 = load_img(path2+str(i)+'.png')  \n",
    "        y = img_to_array(img2)  \n",
    "        y = y.reshape((1,) + y.shape)  \n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        j = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='/home/hp/data/Train/image2', save_format='png', seed = seed):\n",
    "            j += 1\n",
    "            if j > 30:\n",
    "                break  \n",
    "                \n",
    "        j = 0\n",
    "        for batch in datagen.flow(y, batch_size=1,\n",
    "                          save_to_dir='/home/hp/data/Train/label2', save_format='png', seed = seed):\n",
    "            j += 1\n",
    "            if j > 30:\n",
    "                break  \n",
    "        \n",
    "        seed +=2293\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the files in a folder\n",
    "\n",
    "path = '/home/hp/data/Train/image2'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "\n",
    "for file in files:\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, str(i)+'.png'))\n",
    "    i = i+1\n",
    "    \n",
    "path = '/home/hp/data/Train/label2'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "\n",
    "for file in files:\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, str(i)+'.png'))\n",
    "    i = i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3115\n",
      "[[[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [255 255 255 ...   0   0   0]\n",
      "  [255 255 255 ...   0   0   0]\n",
      "  [255 255 255 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [255 255 255 ...   0   0   0]\n",
      "  [255 255 255 ...   0   0   0]\n",
      "  [255 255 255 ...   0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  [255 255 255 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]]\n",
      "(3115, 256, 256)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Conversion of masks to numpy array\n",
    "\n",
    "def Conv_to_NumArr(source, size):\n",
    "    temp_arr = []\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY)\n",
    "        temp_arr.append(thresh)\n",
    "        #print(type(img))\n",
    "    temp = np.array(temp_arr)#https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array\n",
    "    return temp \n",
    "\n",
    "\n",
    "list = os.listdir('/home/hp/data/Train/label2') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Train_data_mask = Conv_to_NumArr('/home/hp/data/Train/label2/', number_files)\n",
    "print(Train_data_mask)\n",
    "print(Train_data_mask.shape)\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3115\n",
      "[[[ 87  83  82 ...  78  78  78]\n",
      "  [ 87  83  82 ...  78  78  78]\n",
      "  [ 87  83  82 ...  78  78  78]\n",
      "  ...\n",
      "  [119 111 103 ...  95  95  95]\n",
      "  [106 106 106 ...  94  94  94]\n",
      "  [ 90 100 108 ...  97  97  97]]\n",
      "\n",
      " [[156 149 132 ... 138 134 135]\n",
      "  [155 155 138 ... 140 139 144]\n",
      "  [142 136 121 ... 148 148 154]\n",
      "  ...\n",
      "  [ 71  75  78 ... 124 127 130]\n",
      "  [ 68  71  72 ... 124 127 130]\n",
      "  [ 68  71  72 ... 124 127 130]]\n",
      "\n",
      " [[156 156 156 ... 163 174 184]\n",
      "  [163 163 163 ... 156 166 176]\n",
      "  [163 163 163 ... 147 155 168]\n",
      "  ...\n",
      "  [134 134 134 ... 160 171 175]\n",
      "  [134 134 134 ... 160 171 175]\n",
      "  [134 134 134 ... 160 171 175]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 48  48  46 ... 111 111 111]\n",
      "  [ 48  48  48 ... 106 106 106]\n",
      "  [ 48  48  49 ... 107 107 107]\n",
      "  ...\n",
      "  [126 130 133 ... 114 114 114]\n",
      "  [127 124 126 ... 123 123 123]\n",
      "  [128 124 127 ... 133 133 133]]\n",
      "\n",
      " [[101 102 111 ...  68  68  68]\n",
      "  [101 102 111 ...  68  68  68]\n",
      "  [101 102 111 ...  68  68  68]\n",
      "  ...\n",
      "  [ 77  89  88 ...  97  97  97]\n",
      "  [ 70  89  91 ...  97  97  97]\n",
      "  [ 72  86  88 ...  97  97  97]]\n",
      "\n",
      " [[190 200 200 ... 144 144 144]\n",
      "  [175 186 192 ... 156 156 156]\n",
      "  [166 171 176 ... 165 165 165]\n",
      "  ...\n",
      "  [180 171 159 ... 140 140 140]\n",
      "  [177 164 146 ... 138 138 138]\n",
      "  [176 163 144 ... 138 138 138]]]\n",
      "(3115, 256, 256)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Conversion of images to numpy array\n",
    "\n",
    "def Conv_to_NumArr(source, size):\n",
    "    temp_arr = []\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #ret,thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY)\n",
    "        temp_arr.append(img)\n",
    "        #print(type(img))\n",
    "    temp = np.array(temp_arr)#https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array\n",
    "    return temp \n",
    "\n",
    "list = os.listdir('/home/hp/data/Train/image2') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Train_data_image = Conv_to_NumArr('/home/hp/data/Train/image2/', number_files)\n",
    "print(Train_data_image)\n",
    "print(Train_data_image.shape)\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the test images\n",
    "\n",
    "def Resize_test(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.resize(img,(256, 256))\n",
    "        cv2.imwrite(\"/home/hp/data/Test/image1/%d.png\"%(j),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Test/image') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Resize_test('/home/hp/data/Test/image/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce binary masks for testing, resize all the masks to 256X256 \n",
    "def Test_to_BinLabel(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        #img1=img[:,:,2]\n",
    "        #img2=(img1!=0)\n",
    "        #plt.imsave(source+str(j)+'.png', ~img[:,:,2], cmap=plt.cm.gray)#grey inverse\n",
    "        #img3 = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        #cv2.imwrite(source+str(j)+'.png', thresh)#final mask\n",
    "        #img4 = cv2.imread(source+str(j)+'.png')\n",
    "        img4 = cv2.resize(img,(256, 256))\n",
    "        ret,thresh = cv2.threshold(img4,0,255,cv2.THRESH_BINARY)\n",
    "        print(thresh)\n",
    "        print(thresh.shape)\n",
    "        print('_'*30)\n",
    "        cv2.imwrite(\"/home/hp/data/Test/label1/%d.png\"%(j),thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ...   0 255 255]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0 255 ...   0   0   0]\n",
      " [  0   0 255 ...   0   0   0]\n",
      " [  0 255 255 ...   0   0   0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[  0   0   0 ... 255 255   0]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[  0   0   0 ... 255   0   0]\n",
      " [  0   0   0 ... 255   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(256, 256)\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Test/label') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Test_to_BinLabel('/home/hp/data/Test/label/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[[201 189 175 ... 188 183 198]\n",
      "  [198 186 175 ... 186 186 215]\n",
      "  [206 186 177 ... 182 184 221]\n",
      "  ...\n",
      "  [199 205 204 ... 121 102  94]\n",
      "  [209 212 211 ... 132 102  89]\n",
      "  [173 177 195 ... 152 109  87]]\n",
      "\n",
      " [[238 238 238 ... 100 200 238]\n",
      "  [238 238 238 ... 128 229 244]\n",
      "  [238 238 238 ... 163 244 247]\n",
      "  ...\n",
      "  [ 57  68  91 ... 122 126 125]\n",
      "  [ 66  59  67 ... 123 123 130]\n",
      "  [ 70  54  53 ... 133 134 139]]\n",
      "\n",
      " [[129 113 123 ...  71  76  74]\n",
      "  [129 109 130 ...  68  70  67]\n",
      "  [124 111 124 ...  65  66  64]\n",
      "  ...\n",
      "  [108 138  83 ... 108  80  97]\n",
      "  [ 95  97  52 ... 116 126  95]\n",
      "  [ 90  74  33 ... 106 125 111]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[164 192 171 ... 149 142 148]\n",
      "  [176 182 171 ... 130 142 156]\n",
      "  [167 166 159 ... 112 124 136]\n",
      "  ...\n",
      "  [216 216 216 ... 191 190 168]\n",
      "  [217 217 216 ... 145 138 126]\n",
      "  [218 218 217 ... 142 144 137]]\n",
      "\n",
      " [[121 118 110 ... 184 191 202]\n",
      "  [112 117 112 ... 205 210 219]\n",
      "  [111 115 108 ... 188 203 213]\n",
      "  ...\n",
      "  [207 192 170 ... 172 140 174]\n",
      "  [210 184 185 ... 174 147 163]\n",
      "  [201 182 205 ... 179 146 151]]\n",
      "\n",
      " [[180 195 210 ...  87 113 137]\n",
      "  [169 166 183 ... 110 136 150]\n",
      "  [171 163 159 ... 125 139 142]\n",
      "  ...\n",
      "  [120 102 162 ...  76  78  46]\n",
      "  [142 131 165 ...  77  60  37]\n",
      "  [136 131 145 ...  79  54  51]]]\n",
      "(8, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Test/image1') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Test_data_image = Conv_to_NumArr('/home/hp/data/Test/image1/', number_files)\n",
    "print(Test_data_image)\n",
    "print(Test_data_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Train_data_image2 ********\n",
      "[[[[-1.1882689 ]\n",
      "   [-1.2801971 ]\n",
      "   [-1.3031793 ]\n",
      "   ...\n",
      "   [-1.3951076 ]\n",
      "   [-1.3951076 ]\n",
      "   [-1.3951076 ]]\n",
      "\n",
      "  [[-1.1882689 ]\n",
      "   [-1.2801971 ]\n",
      "   [-1.3031793 ]\n",
      "   ...\n",
      "   [-1.3951076 ]\n",
      "   [-1.3951076 ]\n",
      "   [-1.3951076 ]]\n",
      "\n",
      "  [[-1.1882689 ]\n",
      "   [-1.2801971 ]\n",
      "   [-1.3031793 ]\n",
      "   ...\n",
      "   [-1.3951076 ]\n",
      "   [-1.3951076 ]\n",
      "   [-1.3951076 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.4528421 ]\n",
      "   [-0.6366988 ]\n",
      "   [-0.82055545]\n",
      "   ...\n",
      "   [-1.0044122 ]\n",
      "   [-1.0044122 ]\n",
      "   [-1.0044122 ]]\n",
      "\n",
      "  [[-0.7516092 ]\n",
      "   [-0.7516092 ]\n",
      "   [-0.7516092 ]\n",
      "   ...\n",
      "   [-1.0273943 ]\n",
      "   [-1.0273943 ]\n",
      "   [-1.0273943 ]]\n",
      "\n",
      "  [[-1.1193225 ]\n",
      "   [-0.8895017 ]\n",
      "   [-0.705645  ]\n",
      "   ...\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]]]\n",
      "\n",
      "\n",
      " [[[ 0.39749515]\n",
      "   [ 0.23662053]\n",
      "   [-0.15407495]\n",
      "   ...\n",
      "   [-0.01618242]\n",
      "   [-0.10811077]\n",
      "   [-0.08512869]]\n",
      "\n",
      "  [[ 0.37451306]\n",
      "   [ 0.37451306]\n",
      "   [-0.01618242]\n",
      "   ...\n",
      "   [ 0.02978175]\n",
      "   [ 0.00679966]\n",
      "   [ 0.1217101 ]]\n",
      "\n",
      "  [[ 0.07574593]\n",
      "   [-0.0621466 ]\n",
      "   [-0.4068779 ]\n",
      "   ...\n",
      "   [ 0.21363844]\n",
      "   [ 0.21363844]\n",
      "   [ 0.35153097]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.5559822 ]\n",
      "   [-1.4640539 ]\n",
      "   [-1.3951076 ]\n",
      "   ...\n",
      "   [-0.33793163]\n",
      "   [-0.2689854 ]\n",
      "   [-0.20003912]]\n",
      "\n",
      "  [[-1.6249285 ]\n",
      "   [-1.5559822 ]\n",
      "   [-1.5330001 ]\n",
      "   ...\n",
      "   [-0.33793163]\n",
      "   [-0.2689854 ]\n",
      "   [-0.20003912]]\n",
      "\n",
      "  [[-1.6249285 ]\n",
      "   [-1.5559822 ]\n",
      "   [-1.5330001 ]\n",
      "   ...\n",
      "   [-0.33793163]\n",
      "   [-0.2689854 ]\n",
      "   [-0.20003912]]]\n",
      "\n",
      "\n",
      " [[[ 0.39749515]\n",
      "   [ 0.39749515]\n",
      "   [ 0.39749515]\n",
      "   ...\n",
      "   [ 0.55836976]\n",
      "   [ 0.8111727 ]\n",
      "   [ 1.0409936 ]]\n",
      "\n",
      "  [[ 0.55836976]\n",
      "   [ 0.55836976]\n",
      "   [ 0.55836976]\n",
      "   ...\n",
      "   [ 0.39749515]\n",
      "   [ 0.627316  ]\n",
      "   [ 0.85713685]]\n",
      "\n",
      "  [[ 0.55836976]\n",
      "   [ 0.55836976]\n",
      "   [ 0.55836976]\n",
      "   ...\n",
      "   [ 0.19065635]\n",
      "   [ 0.37451306]\n",
      "   [ 0.6732802 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.10811077]\n",
      "   [-0.10811077]\n",
      "   [-0.10811077]\n",
      "   ...\n",
      "   [ 0.48942348]\n",
      "   [ 0.7422264 ]\n",
      "   [ 0.8341548 ]]\n",
      "\n",
      "  [[-0.10811077]\n",
      "   [-0.10811077]\n",
      "   [-0.10811077]\n",
      "   ...\n",
      "   [ 0.48942348]\n",
      "   [ 0.7422264 ]\n",
      "   [ 0.8341548 ]]\n",
      "\n",
      "  [[-0.10811077]\n",
      "   [-0.10811077]\n",
      "   [-0.10811077]\n",
      "   ...\n",
      "   [ 0.48942348]\n",
      "   [ 0.7422264 ]\n",
      "   [ 0.8341548 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-2.0845702 ]\n",
      "   [-2.0845702 ]\n",
      "   [-2.1305344 ]\n",
      "   ...\n",
      "   [-0.6366988 ]\n",
      "   [-0.6366988 ]\n",
      "   [-0.6366988 ]]\n",
      "\n",
      "  [[-2.0845702 ]\n",
      "   [-2.0845702 ]\n",
      "   [-2.0845702 ]\n",
      "   ...\n",
      "   [-0.7516092 ]\n",
      "   [-0.7516092 ]\n",
      "   [-0.7516092 ]]\n",
      "\n",
      "  [[-2.0845702 ]\n",
      "   [-2.0845702 ]\n",
      "   [-2.061588  ]\n",
      "   ...\n",
      "   [-0.7286271 ]\n",
      "   [-0.7286271 ]\n",
      "   [-0.7286271 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.29196745]\n",
      "   [-0.20003912]\n",
      "   [-0.13109286]\n",
      "   ...\n",
      "   [-0.5677525 ]\n",
      "   [-0.5677525 ]\n",
      "   [-0.5677525 ]]\n",
      "\n",
      "  [[-0.2689854 ]\n",
      "   [-0.33793163]\n",
      "   [-0.29196745]\n",
      "   ...\n",
      "   [-0.36091372]\n",
      "   [-0.36091372]\n",
      "   [-0.36091372]]\n",
      "\n",
      "  [[-0.24600329]\n",
      "   [-0.33793163]\n",
      "   [-0.2689854 ]\n",
      "   ...\n",
      "   [-0.13109286]\n",
      "   [-0.13109286]\n",
      "   [-0.13109286]]]\n",
      "\n",
      "\n",
      " [[[-0.86651963]\n",
      "   [-0.84353757]\n",
      "   [-0.6366988 ]\n",
      "   ...\n",
      "   [-1.6249285 ]\n",
      "   [-1.6249285 ]\n",
      "   [-1.6249285 ]]\n",
      "\n",
      "  [[-0.86651963]\n",
      "   [-0.84353757]\n",
      "   [-0.6366988 ]\n",
      "   ...\n",
      "   [-1.6249285 ]\n",
      "   [-1.6249285 ]\n",
      "   [-1.6249285 ]]\n",
      "\n",
      "  [[-0.86651963]\n",
      "   [-0.84353757]\n",
      "   [-0.6366988 ]\n",
      "   ...\n",
      "   [-1.6249285 ]\n",
      "   [-1.6249285 ]\n",
      "   [-1.6249285 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.4180897 ]\n",
      "   [-1.1423047 ]\n",
      "   [-1.1652868 ]\n",
      "   ...\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]]\n",
      "\n",
      "  [[-1.5789644 ]\n",
      "   [-1.1423047 ]\n",
      "   [-1.0963405 ]\n",
      "   ...\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]]\n",
      "\n",
      "  [[-1.5330001 ]\n",
      "   [-1.2112509 ]\n",
      "   [-1.1652868 ]\n",
      "   ...\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]\n",
      "   [-0.958448  ]]]\n",
      "\n",
      "\n",
      " [[[ 1.178886  ]\n",
      "   [ 1.4087069 ]\n",
      "   [ 1.4087069 ]\n",
      "   ...\n",
      "   [ 0.1217101 ]\n",
      "   [ 0.1217101 ]\n",
      "   [ 0.1217101 ]]\n",
      "\n",
      "  [[ 0.8341548 ]\n",
      "   [ 1.0869577 ]\n",
      "   [ 1.2248503 ]\n",
      "   ...\n",
      "   [ 0.39749515]\n",
      "   [ 0.39749515]\n",
      "   [ 0.39749515]]\n",
      "\n",
      "  [[ 0.627316  ]\n",
      "   [ 0.7422264 ]\n",
      "   [ 0.85713685]\n",
      "   ...\n",
      "   [ 0.60433394]\n",
      "   [ 0.60433394]\n",
      "   [ 0.60433394]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.9490652 ]\n",
      "   [ 0.7422264 ]\n",
      "   [ 0.4664414 ]\n",
      "   ...\n",
      "   [ 0.02978175]\n",
      "   [ 0.02978175]\n",
      "   [ 0.02978175]]\n",
      "\n",
      "  [[ 0.88011897]\n",
      "   [ 0.5813518 ]\n",
      "   [ 0.16767427]\n",
      "   ...\n",
      "   [-0.01618242]\n",
      "   [-0.01618242]\n",
      "   [-0.01618242]]\n",
      "\n",
      "  [[ 0.85713685]\n",
      "   [ 0.55836976]\n",
      "   [ 0.1217101 ]\n",
      "   ...\n",
      "   [-0.01618242]\n",
      "   [-0.01618242]\n",
      "   [-0.01618242]]]]\n",
      "(3115, 256, 256, 1)\n",
      "******* Train_data_mask2 ********\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "(3115, 256, 256, 1)\n",
      "conv1 shape: (?, 256, 256, 32)\n",
      "pool1 shape: (?, 128, 128, 32)\n",
      "conv2 shape: (?, 128, 128, 64)\n",
      "pool2 shape: (?, 64, 64, 64)\n",
      "conv3 shape: (?, 64, 64, 128)\n",
      "conv3 shape: (?, 64, 64, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:53: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:65: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:72: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:127: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got unet\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  131200      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 64, 64, 256)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  295040      merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 128, 128, 128 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 64) 73792       merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 256, 256, 64) 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 32) 18464       merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 1)  33          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,925,025\n",
      "Trainable params: 1,925,025\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Fitting model...\n",
      "Train on 2492 samples, validate on 623 samples\n",
      "Epoch 1/35\n",
      " - 7465s - loss: 0.2428 - binary_accuracy: 0.8985 - val_loss: 0.1657 - val_binary_accuracy: 0.9314\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.24282, saving model to unet.hdf5\n",
      "Epoch 2/35\n",
      " - 7625s - loss: 0.1402 - binary_accuracy: 0.9421 - val_loss: 0.1117 - val_binary_accuracy: 0.9538\n",
      "\n",
      "Epoch 00002: loss improved from 0.24282 to 0.14017, saving model to unet.hdf5\n",
      "Epoch 3/35\n",
      " - 7912s - loss: 0.0956 - binary_accuracy: 0.9602 - val_loss: 0.0843 - val_binary_accuracy: 0.9646\n",
      "\n",
      "Epoch 00003: loss improved from 0.14017 to 0.09557, saving model to unet.hdf5\n",
      "Epoch 4/35\n",
      " - 8673s - loss: 0.0749 - binary_accuracy: 0.9685 - val_loss: 0.0714 - val_binary_accuracy: 0.9697\n",
      "\n",
      "Epoch 00004: loss improved from 0.09557 to 0.07495, saving model to unet.hdf5\n",
      "Epoch 5/35\n",
      " - 9442s - loss: 0.0632 - binary_accuracy: 0.9733 - val_loss: 0.0604 - val_binary_accuracy: 0.9745\n",
      "\n",
      "Epoch 00005: loss improved from 0.07495 to 0.06316, saving model to unet.hdf5\n",
      "Epoch 6/35\n",
      " - 9118s - loss: 0.0540 - binary_accuracy: 0.9770 - val_loss: 0.0558 - val_binary_accuracy: 0.9764\n",
      "\n",
      "Epoch 00006: loss improved from 0.06316 to 0.05402, saving model to unet.hdf5\n",
      "Epoch 7/35\n",
      " - 8613s - loss: 0.0508 - binary_accuracy: 0.9785 - val_loss: 0.0502 - val_binary_accuracy: 0.9788\n",
      "\n",
      "Epoch 00007: loss improved from 0.05402 to 0.05078, saving model to unet.hdf5\n",
      "Epoch 8/35\n",
      " - 7303s - loss: 0.0437 - binary_accuracy: 0.9813 - val_loss: 0.0471 - val_binary_accuracy: 0.9802\n",
      "\n",
      "Epoch 00008: loss improved from 0.05078 to 0.04369, saving model to unet.hdf5\n",
      "Epoch 9/35\n",
      " - 7275s - loss: 0.0405 - binary_accuracy: 0.9826 - val_loss: 0.0458 - val_binary_accuracy: 0.9807\n",
      "\n",
      "Epoch 00009: loss improved from 0.04369 to 0.04049, saving model to unet.hdf5\n",
      "Epoch 10/35\n",
      " - 7294s - loss: 0.0379 - binary_accuracy: 0.9837 - val_loss: 0.0443 - val_binary_accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: loss improved from 0.04049 to 0.03795, saving model to unet.hdf5\n",
      "Epoch 11/35\n",
      " - 7408s - loss: 0.0357 - binary_accuracy: 0.9846 - val_loss: 0.0424 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00011: loss improved from 0.03795 to 0.03570, saving model to unet.hdf5\n",
      "Epoch 12/35\n",
      " - 7488s - loss: 0.0333 - binary_accuracy: 0.9856 - val_loss: 0.0418 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00012: loss improved from 0.03570 to 0.03326, saving model to unet.hdf5\n",
      "Epoch 13/35\n",
      " - 8826s - loss: 0.0347 - binary_accuracy: 0.9852 - val_loss: 0.0396 - val_binary_accuracy: 0.9836\n",
      "\n",
      "Epoch 00013: loss did not improve\n",
      "Epoch 14/35\n",
      " - 8623s - loss: 0.0296 - binary_accuracy: 0.9872 - val_loss: 0.0385 - val_binary_accuracy: 0.9841\n",
      "\n",
      "Epoch 00014: loss improved from 0.03326 to 0.02958, saving model to unet.hdf5\n",
      "Epoch 15/35\n",
      " - 8133s - loss: 0.0299 - binary_accuracy: 0.9871 - val_loss: 0.0388 - val_binary_accuracy: 0.9841\n",
      "\n",
      "Epoch 00015: loss did not improve\n",
      "Epoch 16/35\n",
      " - 7929s - loss: 0.0285 - binary_accuracy: 0.9877 - val_loss: 0.0388 - val_binary_accuracy: 0.9841\n",
      "\n",
      "Epoch 00016: loss improved from 0.02958 to 0.02847, saving model to unet.hdf5\n",
      "Epoch 17/35\n",
      " - 8710s - loss: 0.0278 - binary_accuracy: 0.9880 - val_loss: 0.0504 - val_binary_accuracy: 0.9796\n",
      "\n",
      "Epoch 00017: loss improved from 0.02847 to 0.02784, saving model to unet.hdf5\n",
      "Epoch 18/35\n",
      " - 8193s - loss: 0.0266 - binary_accuracy: 0.9885 - val_loss: 0.0377 - val_binary_accuracy: 0.9847\n",
      "\n",
      "Epoch 00018: loss improved from 0.02784 to 0.02663, saving model to unet.hdf5\n",
      "Epoch 19/35\n",
      " - 7399s - loss: 0.0258 - binary_accuracy: 0.9888 - val_loss: 0.0371 - val_binary_accuracy: 0.9851\n",
      "\n",
      "Epoch 00019: loss improved from 0.02663 to 0.02580, saving model to unet.hdf5\n",
      "Epoch 20/35\n",
      " - 7391s - loss: 0.0293 - binary_accuracy: 0.9876 - val_loss: 0.0363 - val_binary_accuracy: 0.9855\n",
      "\n",
      "Epoch 00020: loss did not improve\n",
      "Epoch 21/35\n",
      " - 7406s - loss: 0.0234 - binary_accuracy: 0.9899 - val_loss: 0.0368 - val_binary_accuracy: 0.9855\n",
      "\n",
      "Epoch 00021: loss improved from 0.02580 to 0.02344, saving model to unet.hdf5\n",
      "Epoch 22/35\n",
      " - 7458s - loss: 0.0237 - binary_accuracy: 0.9897 - val_loss: 0.0368 - val_binary_accuracy: 0.9853\n",
      "\n",
      "Epoch 00022: loss did not improve\n",
      "Epoch 23/35\n",
      " - 7398s - loss: 0.0233 - binary_accuracy: 0.9899 - val_loss: 0.0365 - val_binary_accuracy: 0.9856\n",
      "\n",
      "Epoch 00023: loss improved from 0.02344 to 0.02329, saving model to unet.hdf5\n",
      "Epoch 24/35\n",
      " - 7891s - loss: 0.0237 - binary_accuracy: 0.9898 - val_loss: 0.0368 - val_binary_accuracy: 0.9857\n",
      "\n",
      "Epoch 00024: loss did not improve\n",
      "Epoch 25/35\n",
      " - 9588s - loss: 0.0219 - binary_accuracy: 0.9905 - val_loss: 0.0381 - val_binary_accuracy: 0.9852\n",
      "\n",
      "Epoch 00025: loss improved from 0.02329 to 0.02190, saving model to unet.hdf5\n",
      "Epoch 26/35\n",
      " - 8226s - loss: 0.0222 - binary_accuracy: 0.9904 - val_loss: 0.0359 - val_binary_accuracy: 0.9861\n",
      "\n",
      "Epoch 00026: loss did not improve\n",
      "Epoch 27/35\n",
      " - 9190s - loss: 0.0212 - binary_accuracy: 0.9908 - val_loss: 0.0368 - val_binary_accuracy: 0.9859\n",
      "\n",
      "Epoch 00027: loss improved from 0.02190 to 0.02121, saving model to unet.hdf5\n",
      "Epoch 28/35\n",
      " - 9159s - loss: 0.0209 - binary_accuracy: 0.9910 - val_loss: 0.0368 - val_binary_accuracy: 0.9859\n",
      "\n",
      "Epoch 00028: loss improved from 0.02121 to 0.02088, saving model to unet.hdf5\n",
      "Epoch 29/35\n",
      " - 7531s - loss: 0.0206 - binary_accuracy: 0.9911 - val_loss: 0.0367 - val_binary_accuracy: 0.9862\n",
      "\n",
      "Epoch 00029: loss improved from 0.02088 to 0.02056, saving model to unet.hdf5\n",
      "Epoch 30/35\n",
      " - 7394s - loss: 0.0203 - binary_accuracy: 0.9913 - val_loss: 0.0375 - val_binary_accuracy: 0.9861\n",
      "\n",
      "Epoch 00030: loss improved from 0.02056 to 0.02031, saving model to unet.hdf5\n",
      "Epoch 31/35\n",
      " - 7361s - loss: 0.0196 - binary_accuracy: 0.9915 - val_loss: 0.0365 - val_binary_accuracy: 0.9860\n",
      "\n",
      "Epoch 00031: loss improved from 0.02031 to 0.01964, saving model to unet.hdf5\n",
      "Epoch 32/35\n",
      " - 7344s - loss: 0.0193 - binary_accuracy: 0.9917 - val_loss: 0.0375 - val_binary_accuracy: 0.9862\n",
      "\n",
      "Epoch 00032: loss improved from 0.01964 to 0.01933, saving model to unet.hdf5\n",
      "Epoch 33/35\n",
      " - 7355s - loss: 0.0190 - binary_accuracy: 0.9918 - val_loss: 0.0391 - val_binary_accuracy: 0.9855\n",
      "\n",
      "Epoch 00033: loss improved from 0.01933 to 0.01905, saving model to unet.hdf5\n",
      "Epoch 34/35\n",
      " - 7305s - loss: 0.0186 - binary_accuracy: 0.9920 - val_loss: 0.0376 - val_binary_accuracy: 0.9864\n",
      "\n",
      "Epoch 00034: loss improved from 0.01905 to 0.01857, saving model to unet.hdf5\n",
      "Epoch 35/35\n",
      " - 8385s - loss: 0.0183 - binary_accuracy: 0.9921 - val_loss: 0.0374 - val_binary_accuracy: 0.9863\n",
      "\n",
      "Epoch 00035: loss improved from 0.01857 to 0.01828, saving model to unet.hdf5\n",
      "predict test data\n",
      "8/8 [==============================] - 13s 2s/step\n",
      "***** segmented_img before thresholding *****\n",
      "[[[[3.62887643e-02]\n",
      "   [1.06612444e-02]\n",
      "   [1.17379893e-02]\n",
      "   ...\n",
      "   [6.19572587e-04]\n",
      "   [1.29347516e-03]\n",
      "   [8.96108896e-03]]\n",
      "\n",
      "  [[1.05943680e-02]\n",
      "   [1.16643962e-03]\n",
      "   [1.11605518e-03]\n",
      "   ...\n",
      "   [9.39635720e-06]\n",
      "   [7.56551599e-05]\n",
      "   [3.59977479e-04]]\n",
      "\n",
      "  [[3.06875305e-03]\n",
      "   [1.73871435e-04]\n",
      "   [8.95652483e-05]\n",
      "   ...\n",
      "   [3.71615130e-08]\n",
      "   [8.36646734e-07]\n",
      "   [2.83584741e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.35330624e-05]\n",
      "   [1.09578068e-07]\n",
      "   [3.13378088e-08]\n",
      "   ...\n",
      "   [1.89999521e-01]\n",
      "   [6.46141052e-01]\n",
      "   [8.79025400e-01]]\n",
      "\n",
      "  [[2.21918119e-04]\n",
      "   [1.80426900e-06]\n",
      "   [4.21101163e-07]\n",
      "   ...\n",
      "   [1.36489525e-01]\n",
      "   [5.18300653e-01]\n",
      "   [8.46339047e-01]]\n",
      "\n",
      "  [[2.60994653e-03]\n",
      "   [1.61387987e-04]\n",
      "   [2.45802294e-05]\n",
      "   ...\n",
      "   [2.45921567e-01]\n",
      "   [5.63853800e-01]\n",
      "   [6.84958696e-01]]]\n",
      "\n",
      "\n",
      " [[[3.87975131e-04]\n",
      "   [1.59930528e-06]\n",
      "   [2.50374256e-07]\n",
      "   ...\n",
      "   [8.25798869e-01]\n",
      "   [2.91158915e-01]\n",
      "   [3.97168279e-01]]\n",
      "\n",
      "  [[4.89207059e-06]\n",
      "   [1.46820700e-09]\n",
      "   [1.32167124e-10]\n",
      "   ...\n",
      "   [8.90908003e-01]\n",
      "   [4.91540939e-01]\n",
      "   [2.58432448e-01]]\n",
      "\n",
      "  [[9.41946610e-08]\n",
      "   [4.37962340e-12]\n",
      "   [7.90197375e-14]\n",
      "   ...\n",
      "   [8.66290689e-01]\n",
      "   [2.65838474e-01]\n",
      "   [4.07809727e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.99992609e-01]\n",
      "   [9.99991775e-01]\n",
      "   [9.99966621e-01]\n",
      "   ...\n",
      "   [8.34262073e-02]\n",
      "   [8.55635703e-02]\n",
      "   [4.39791083e-02]]\n",
      "\n",
      "  [[9.99991298e-01]\n",
      "   [9.99999046e-01]\n",
      "   [9.99997377e-01]\n",
      "   ...\n",
      "   [2.15737224e-01]\n",
      "   [3.37017328e-01]\n",
      "   [2.68749118e-01]]\n",
      "\n",
      "  [[9.98140454e-01]\n",
      "   [9.99951005e-01]\n",
      "   [9.99961972e-01]\n",
      "   ...\n",
      "   [5.62695801e-01]\n",
      "   [5.43923855e-01]\n",
      "   [5.35517037e-01]]]\n",
      "\n",
      "\n",
      " [[[3.28135975e-02]\n",
      "   [3.79523612e-03]\n",
      "   [9.01084801e-04]\n",
      "   ...\n",
      "   [9.94884551e-01]\n",
      "   [9.81935263e-01]\n",
      "   [9.55829382e-01]]\n",
      "\n",
      "  [[6.90308586e-03]\n",
      "   [2.81162589e-04]\n",
      "   [4.16702678e-05]\n",
      "   ...\n",
      "   [9.99931335e-01]\n",
      "   [9.99544561e-01]\n",
      "   [9.95075405e-01]]\n",
      "\n",
      "  [[6.42731786e-04]\n",
      "   [1.52684679e-05]\n",
      "   [2.09127825e-06]\n",
      "   ...\n",
      "   [9.99988437e-01]\n",
      "   [9.99874234e-01]\n",
      "   [9.98610973e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.92176116e-01]\n",
      "   [9.99829292e-01]\n",
      "   [9.99999762e-01]\n",
      "   ...\n",
      "   [8.65435719e-01]\n",
      "   [6.38512135e-01]\n",
      "   [2.46072114e-01]]\n",
      "\n",
      "  [[9.96048510e-01]\n",
      "   [9.99967337e-01]\n",
      "   [9.99999881e-01]\n",
      "   ...\n",
      "   [7.71893263e-01]\n",
      "   [5.54126441e-01]\n",
      "   [3.32262784e-01]]\n",
      "\n",
      "  [[9.89784300e-01]\n",
      "   [9.99693036e-01]\n",
      "   [9.99998331e-01]\n",
      "   ...\n",
      "   [4.90920722e-01]\n",
      "   [3.69265467e-01]\n",
      "   [4.00098950e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[2.34179702e-02]\n",
      "   [6.34724973e-03]\n",
      "   [4.87469602e-03]\n",
      "   ...\n",
      "   [9.64033723e-01]\n",
      "   [9.53402579e-01]\n",
      "   [9.02477503e-01]]\n",
      "\n",
      "  [[8.73016939e-03]\n",
      "   [1.97785697e-03]\n",
      "   [8.96453974e-04]\n",
      "   ...\n",
      "   [9.81377304e-01]\n",
      "   [9.76842523e-01]\n",
      "   [9.55876112e-01]]\n",
      "\n",
      "  [[1.99093344e-03]\n",
      "   [4.96858149e-04]\n",
      "   [2.87240488e-04]\n",
      "   ...\n",
      "   [9.97740030e-01]\n",
      "   [9.95130062e-01]\n",
      "   [9.86201704e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.33781848e-05]\n",
      "   [4.24869784e-09]\n",
      "   [9.19078480e-10]\n",
      "   ...\n",
      "   [4.05908184e-04]\n",
      "   [1.54754124e-03]\n",
      "   [1.49503015e-02]]\n",
      "\n",
      "  [[7.89676706e-05]\n",
      "   [1.16824587e-07]\n",
      "   [4.00578237e-08]\n",
      "   ...\n",
      "   [5.03215101e-03]\n",
      "   [8.27462599e-03]\n",
      "   [5.09473793e-02]]\n",
      "\n",
      "  [[1.39206578e-03]\n",
      "   [7.47358936e-05]\n",
      "   [2.03542731e-05]\n",
      "   ...\n",
      "   [2.35127546e-02]\n",
      "   [5.17229997e-02]\n",
      "   [1.49410352e-01]]]\n",
      "\n",
      "\n",
      " [[[2.77010947e-01]\n",
      "   [2.50321567e-01]\n",
      "   [2.34820306e-01]\n",
      "   ...\n",
      "   [1.75271282e-06]\n",
      "   [2.91774195e-05]\n",
      "   [3.38961091e-03]]\n",
      "\n",
      "  [[1.23344690e-01]\n",
      "   [7.19072074e-02]\n",
      "   [7.24457726e-02]\n",
      "   ...\n",
      "   [1.07427800e-09]\n",
      "   [1.85603511e-07]\n",
      "   [9.21730170e-05]]\n",
      "\n",
      "  [[2.79012658e-02]\n",
      "   [4.61059855e-03]\n",
      "   [4.76080459e-03]\n",
      "   ...\n",
      "   [2.99649333e-11]\n",
      "   [3.14075055e-09]\n",
      "   [5.84209101e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.65840448e-03]\n",
      "   [1.52948938e-04]\n",
      "   [1.71920310e-05]\n",
      "   ...\n",
      "   [1.29720217e-08]\n",
      "   [2.21870920e-07]\n",
      "   [3.22857049e-05]]\n",
      "\n",
      "  [[1.27012946e-03]\n",
      "   [4.63122524e-05]\n",
      "   [1.98194703e-05]\n",
      "   ...\n",
      "   [1.12767813e-08]\n",
      "   [1.60765012e-07]\n",
      "   [3.69104564e-05]]\n",
      "\n",
      "  [[4.99865226e-03]\n",
      "   [5.61933033e-04]\n",
      "   [4.49108629e-04]\n",
      "   ...\n",
      "   [7.33533454e-07]\n",
      "   [8.62632260e-06]\n",
      "   [5.56668791e-04]]]\n",
      "\n",
      "\n",
      " [[[9.22694243e-03]\n",
      "   [6.52002578e-04]\n",
      "   [2.05091565e-04]\n",
      "   ...\n",
      "   [2.10679144e-01]\n",
      "   [1.69430509e-01]\n",
      "   [2.57751346e-01]]\n",
      "\n",
      "  [[8.51456833e-04]\n",
      "   [1.19639291e-04]\n",
      "   [5.29246681e-05]\n",
      "   ...\n",
      "   [3.03745922e-02]\n",
      "   [2.64650378e-02]\n",
      "   [5.67101501e-02]]\n",
      "\n",
      "  [[1.52118341e-03]\n",
      "   [8.61234148e-04]\n",
      "   [1.08365167e-03]\n",
      "   ...\n",
      "   [3.18794399e-02]\n",
      "   [5.00674127e-03]\n",
      "   [2.53383815e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.93696283e-03]\n",
      "   [2.78173884e-05]\n",
      "   [3.35585185e-07]\n",
      "   ...\n",
      "   [9.99999881e-01]\n",
      "   [9.99999881e-01]\n",
      "   [9.99998689e-01]]\n",
      "\n",
      "  [[1.10990263e-03]\n",
      "   [2.75368220e-05]\n",
      "   [7.60431249e-07]\n",
      "   ...\n",
      "   [9.99999881e-01]\n",
      "   [9.99999881e-01]\n",
      "   [9.99995828e-01]]\n",
      "\n",
      "  [[9.95754031e-04]\n",
      "   [1.09296081e-04]\n",
      "   [1.86877114e-05]\n",
      "   ...\n",
      "   [9.99963284e-01]\n",
      "   [9.99929547e-01]\n",
      "   [9.99507189e-01]]]]\n",
      "------------------------------------------------------------\n",
      "***** segmented_img after thresholding *****\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]]\n",
      "dict_keys(['val_binary_accuracy', 'val_loss', 'loss', 'binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc35122748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc38cc4160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to image\n"
     ]
    }
   ],
   "source": [
    "#Defining the U-Net model\n",
    "\n",
    "#class myUnet(object):\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "smooth = 1\n",
    "\n",
    "\n",
    "'''def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return (1-dice_coef(y_true, y_pred))'''\n",
    "        \n",
    "def get_unet():\n",
    "\n",
    "        #inputs = Input((self.img_rows, self.img_cols,3))\n",
    "        inputs = Input((img_rows, img_cols, 1))\n",
    "        \n",
    "        conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print(\"conv1 shape:\",conv1.shape)\n",
    "        conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        #print( \"conv1 shape:\",conv1.shape)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print(\"pool1 shape:\",pool1.shape)\n",
    "        \n",
    "        conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print( \"conv2 shape:\",conv2.shape)\n",
    "        conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "       # print( \"conv2 shape:\",conv2.shape)\n",
    "        #drop2 = Dropout(0.5)(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print( \"pool2 shape:\",pool2.shape)\n",
    "        \n",
    "        conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print(\"conv3 shape:\",conv3.shape)\n",
    "        conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        #print(\"conv3 shape:\",conv3.shape)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        #print(\"pool3 shape:\",pool3.shape)\n",
    "        #drop3 = Dropout(0.5)(conv3)\n",
    "        \n",
    "        conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        print(\"conv3 shape:\",conv3.shape)\n",
    "        conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        #pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        \n",
    "        up5 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv4))\n",
    "        merge5 = merge([conv3,up5], mode = 'concat', concat_axis = 3)\n",
    "        conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
    "        #drop4 = Dropout(0.1)(conv4)\n",
    "        conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        \n",
    "        up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "        merge6 = merge([conv2,up6], mode = 'concat', concat_axis = 3)\n",
    "        conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        #drop5 = Dropout(0.1)(conv5)\n",
    "        conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "        \n",
    "        up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = merge([conv1,up7], mode = 'concat', concat_axis = 3)\n",
    "        conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        #drop5 = Dropout(0.1)(conv5)\n",
    "        conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "      \n",
    "        conv8 = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "        \n",
    "        model = Model(input = inputs, output = conv8)\n",
    "\n",
    "        #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "                \n",
    "        optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.00000001, decay=0.0)\n",
    "        #model.compile(optimizer = optimizer, loss = dice_coef_loss, metrics=[dice_coef])\n",
    "        model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "'''def resize_arr(imgs):\n",
    "        imgsp = np.ndarray((1,imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            imgsp[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "        #imgsp = imgsp[..., np.newaxis]\n",
    "        imgsp = np.expand_dims(imgsp, axis=1)\n",
    "        return imgsp'''\n",
    "    \n",
    "def resize_arr(imgs):\n",
    "        imgsp = imgs.reshape((imgs.shape[0], img_cols, img_rows, 1))\n",
    "        return imgsp\n",
    "    \n",
    "def train():\n",
    "\n",
    "        #print(\"loading data\")\n",
    "        #imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        #print(\"loading data done\")\n",
    "        Train_data_image2 = resize_arr(Train_data_image)\n",
    "        Train_data_mask2 = resize_arr(Train_data_mask)\n",
    "        \n",
    "        Train_data_image2 = Train_data_image2.astype('float32')\n",
    "        mean = np.mean(Train_data_image2)  # mean for data centering\n",
    "        std = np.std(Train_data_image2)  # std for data normalization\n",
    "\n",
    "        Train_data_image2 -= mean\n",
    "        Train_data_image2 /= std\n",
    "        print(\"******* Train_data_image2 ********\")\n",
    "        print(Train_data_image2)\n",
    "        print(Train_data_image2.shape)\n",
    "\n",
    "        Train_data_mask2  = Train_data_mask2.astype('float32')\n",
    "        Train_data_mask2  /= 255. # scale masks to [0, 1]\n",
    "        print(\"******* Train_data_mask2 ********\")\n",
    "        print(Train_data_mask2)\n",
    "        print(Train_data_mask2.shape)\n",
    "        \n",
    "        #np.reshape(a, (2, 3)) \n",
    "        #np.reshape(Train_data_image[0][0], (512, 512, 3)) \n",
    "            \n",
    "        model = get_unet()\n",
    "        print(\"got unet\")\n",
    "        model.summary()\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "        print('Fitting model...')\n",
    "        history = model.fit(Train_data_image2, Train_data_mask2, batch_size=1, nb_epoch=35, verbose=2, validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "        \n",
    "        #model.load_weights('unet.hdf5')\n",
    "        \n",
    "        Test_data_image2 = resize_arr(Test_data_image)\n",
    "            \n",
    "        Test_data_image2 =  Test_data_image2.astype('float32')\n",
    "        Test_data_image2 -= mean\n",
    "        Test_data_image2 /= std \n",
    "        \n",
    "        #Test_data_mask2 = resize_arr(Test_data_mask)\n",
    "            \n",
    "        #Test_data_mask2  = Test_data_mask2.astype('float32')\n",
    "        #Test_data_mask2  /= 255.\n",
    "        \n",
    "        print('predict test data')\n",
    "        Test_data_mask_predict = model.predict(Test_data_image2, batch_size=1, verbose=1)\n",
    "        #print(Test_data_mask_predict)\n",
    "        #Test_data_mask_predict[Test_data_mask_predict>0.5]=1\n",
    "        #Test_data_mask_predict[Test_data_mask_predict<=0.5]=0\n",
    "        #print(Test_data_mask_predict)\n",
    "        np.save('/home/hp/data/Test_data_mask_predict.npy', Test_data_mask_predict)\n",
    "        segmented_img = np.load('/home/hp/data/Test_data_mask_predict.npy')\n",
    "        print(\"***** segmented_img before thresholding *****\")\n",
    "        print(segmented_img)\n",
    "        print('-'*60)\n",
    "        segmented_img[segmented_img>0.5] = 1\n",
    "        segmented_img[segmented_img<=0.5] = 0\n",
    "        print(\"***** segmented_img after thresholding *****\")\n",
    "        print(segmented_img)\n",
    "        np.save('/home/hp/data/segmented_img.npy', segmented_img)\n",
    "       \n",
    "        # list all data in history\n",
    "        print(history.history.keys())\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['binary_accuracy'])\n",
    "        plt.plot(history.history['val_binary_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show() \n",
    "        \n",
    "        \n",
    "        # summarize history for accuracy\n",
    "        '''plt.plot(history.history['dice_coef'])\n",
    "        plt.plot(history.history['val_dice_coef'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('segmentation accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show() ''' \n",
    "        \n",
    "def save_img():\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load('/home/hp/data/segmented_img.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"/home/hp/data/Result/%d.png\"%(i+1))\n",
    "            \n",
    "#if __name__ == '__main__':\n",
    "#myunet = myUnet()\n",
    "#Train_data_image = myunet.resizei(Train_data_image)\n",
    "#Train_data_mask = myunet.resizei(Train_data_mask)\n",
    "#Test_data_image = myunet.resizei(Test_data_image)\n",
    "\n",
    "train()\n",
    "save_img()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False  True  True]\n",
      " [False False False ... False  True  True]\n",
      " [False False False ... False  True  True]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ... False  True  True]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[False False False ...  True False False]\n",
      " [False False False ...  True False False]\n",
      " [False False False ...  True False False]\n",
      " ...\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 1. ... 1. 1. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "[[False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True False]\n",
      " [ True  True  True ...  True  True False]\n",
      " [ True  True  True ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False  True ... False False False]\n",
      " [False False  True ... False False False]\n",
      " [False  True  True ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True False False]\n",
      " ...\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ...  True  True False]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n",
      "[[False False False ...  True False False]\n",
      " [False False False ...  True False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0.75577183 0.56661485 0.54975499 0.62445367 0.86760874 0.79962292\n",
      " 0.56655162 0.74501837]\n",
      "0.6844246242424419\n"
     ]
    }
   ],
   "source": [
    "def dice_coef(seg, gt):\n",
    "    if seg.shape != gt.shape:\n",
    "        raise ValueError(\"Shape mismatch: seg and gt must have to be of the same shape.\")\n",
    "    else:\n",
    "        intersection = np.logical_and(seg, gt)\n",
    "        value = (2. * intersection.sum())  / (seg.sum() + gt.sum())\n",
    "    return value\n",
    "\n",
    "path = '/home/hp/data/Result/'\n",
    "path2 = '/home/hp/data/Test/label1/'\n",
    "list = os.listdir('/home/hp/data/Test/label1/') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for j in range(1,size+1): \n",
    "    seg=mpimg.imread(path+str(j)+'.png')\n",
    "    print(\"printing segmented_img\")\n",
    "    print(seg)\n",
    "    seg = np.asarray(seg).astype(np.bool)\n",
    "    print(seg)\n",
    "    print('-'*80)\n",
    "    print(\"printing test labels\")\n",
    "    gt=mpimg.imread(path2+str(j)+'.png')\n",
    "    print(gt)\n",
    "    gt = np.asarray(gt).astype(np.bool)\n",
    "    print(gt)\n",
    "    print('%'*80)\n",
    "    value = dice_coef(seg, gt)\n",
    "    accuracy.append(value)  \n",
    "    \n",
    "#print(accuracy)\n",
    "accu = np.array(accuracy) \n",
    "print(accu)\n",
    "print(accu.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
