{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "#seed = 7\n",
    "#np.random.seed(seed)\n",
    "#####################################\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "#####################################\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce binary masks for training, resize all the masks to 500X500 \n",
    "def Label_to_BinLabel(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #print(img.shape)\n",
    "        #cv2.imwrite(source+str(j)+'.png', thresh)#final mask\n",
    "        #img4 = cv2.imread(source+str(j)+'.png')\n",
    "        img4 = cv2.resize(img,(500, 500))\n",
    "        ret,thresh = cv2.threshold(img4,0,255,cv2.THRESH_BINARY)\n",
    "        print(thresh)\n",
    "        print(thresh.shape)\n",
    "        print('_'*40)\n",
    "        cv2.imwrite(\"/home/hp/data/Train/label1/%d.png\"%(j),thresh)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0 255 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " ...\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]]\n",
      "(500, 500)\n",
      "________________________________________\n",
      "[[  0   0   0 ...   0   0 255]\n",
      " [  0   0   0 ...   0 255 255]\n",
      " [  0   0   0 ...   0 255 255]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n",
      "(500, 500)\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Train/label') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Label_to_BinLabel('/home/hp/data/Train/label/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize all of 24 train images to 500X500\n",
    "def Resize_images(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')        \n",
    "        img = cv2.resize(img,(500, 500))\n",
    "        print(img)\n",
    "        print(img.shape)\n",
    "        cv2.imwrite(\"/home/hp/data/Train/image1/%d.png\"%(j),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[[[226 194 220]\n",
      "  [236 185 214]\n",
      "  [247 177 207]\n",
      "  ...\n",
      "  [214 169 194]\n",
      "  [199 175 199]\n",
      "  [222 188 217]]\n",
      "\n",
      " [[228 189 215]\n",
      "  [236 181 209]\n",
      "  [246 173 203]\n",
      "  ...\n",
      "  [230 173 200]\n",
      "  [220 183 212]\n",
      "  [244 194 229]]\n",
      "\n",
      " [[232 185 211]\n",
      "  [238 177 205]\n",
      "  [245 170 200]\n",
      "  ...\n",
      "  [244 176 206]\n",
      "  [244 191 224]\n",
      "  [255 201 239]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[222 175 251]\n",
      "  [221 172 250]\n",
      "  [225 176 247]\n",
      "  ...\n",
      "  [190  77 108]\n",
      "  [177  72  98]\n",
      "  [161  68  87]]\n",
      "\n",
      " [[233 163 206]\n",
      "  [226 158 194]\n",
      "  [225 161 189]\n",
      "  ...\n",
      "  [185  78 116]\n",
      "  [176  69 101]\n",
      "  [160  66  88]]\n",
      "\n",
      " [[244 138 197]\n",
      "  [235 138 194]\n",
      "  [229 146 196]\n",
      "  ...\n",
      "  [169  89 105]\n",
      "  [133  82  88]\n",
      "  [147  72  84]]]\n",
      "(500, 500, 3)\n",
      "[[[239 236 243]\n",
      "  [239 236 243]\n",
      "  [239 236 243]\n",
      "  ...\n",
      "  [243 224 230]\n",
      "  [243 232 233]\n",
      "  [243 242 238]]\n",
      "\n",
      " [[239 236 243]\n",
      "  [239 236 243]\n",
      "  [239 236 243]\n",
      "  ...\n",
      "  [243 228 234]\n",
      "  [243 236 236]\n",
      "  [243 244 240]]\n",
      "\n",
      " [[239 236 243]\n",
      "  [239 236 243]\n",
      "  [239 236 243]\n",
      "  ...\n",
      "  [243 235 239]\n",
      "  [243 241 241]\n",
      "  [243 247 244]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 40  33 145]\n",
      "  [ 42  40 131]\n",
      "  [ 47  27 118]\n",
      "  ...\n",
      "  [151  88 199]\n",
      "  [152  89 208]\n",
      "  [154  94 206]]\n",
      "\n",
      " [[ 41  38 146]\n",
      "  [ 47  34 150]\n",
      "  [ 47  28 108]\n",
      "  ...\n",
      "  [158  99 203]\n",
      "  [159  99 208]\n",
      "  [160 103 206]]\n",
      "\n",
      " [[ 43  42 143]\n",
      "  [ 51  28 153]\n",
      "  [ 47  30 123]\n",
      "  ...\n",
      "  [158 104 202]\n",
      "  [159 103 201]\n",
      "  [161 104 199]]]\n",
      "(500, 500, 3)\n",
      "[[[139  99 180]\n",
      "  [158  92 192]\n",
      "  [131  88 168]\n",
      "  ...\n",
      "  [ 87  47 146]\n",
      "  [ 86  45 139]\n",
      "  [ 85  43 129]]\n",
      "\n",
      " [[144 100 184]\n",
      "  [154  89 194]\n",
      "  [129  86 162]\n",
      "  ...\n",
      "  [ 87  44 141]\n",
      "  [ 86  43 135]\n",
      "  [ 84  40 126]]\n",
      "\n",
      " [[151 100 190]\n",
      "  [149  85 195]\n",
      "  [128  84 155]\n",
      "  ...\n",
      "  [ 86  40 134]\n",
      "  [ 85  38 129]\n",
      "  [ 83  36 122]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[117  68 163]\n",
      "  [100  55 136]\n",
      "  [131  57 156]\n",
      "  ...\n",
      "  [145  99 204]\n",
      "  [138  79 170]\n",
      "  [128  58 130]]\n",
      "\n",
      " [[122  64 153]\n",
      "  [ 98  51 135]\n",
      "  [120  49 136]\n",
      "  ...\n",
      "  [144 107 228]\n",
      "  [140  87 193]\n",
      "  [135  64 148]]\n",
      "\n",
      " [[129  60 139]\n",
      "  [108  51 150]\n",
      "  [118  46 130]\n",
      "  ...\n",
      "  [136  94 193]\n",
      "  [136  83 182]\n",
      "  [135  70 170]]]\n",
      "(500, 500, 3)\n",
      "[[[104  34  59]\n",
      "  [ 97  33  61]\n",
      "  [ 94  35  80]\n",
      "  ...\n",
      "  [ 66  27  48]\n",
      "  [ 71  28  55]\n",
      "  [ 76  32  66]]\n",
      "\n",
      " [[ 97  29  48]\n",
      "  [ 90  26  53]\n",
      "  [ 87  28  70]\n",
      "  ...\n",
      "  [ 65  23  50]\n",
      "  [ 73  28  60]\n",
      "  [ 84  38  76]]\n",
      "\n",
      " [[ 91  25  49]\n",
      "  [ 85  22  53]\n",
      "  [ 82  23  63]\n",
      "  ...\n",
      "  [ 67  25  64]\n",
      "  [ 76  34  77]\n",
      "  [ 91  48  95]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[137  75 128]\n",
      "  [129  59  97]\n",
      "  [120  43  74]\n",
      "  ...\n",
      "  [134  73 166]\n",
      "  [141  79 181]\n",
      "  [149  86 193]]\n",
      "\n",
      " [[150  98 168]\n",
      "  [141  77 129]\n",
      "  [129  55  96]\n",
      "  ...\n",
      "  [129  73 166]\n",
      "  [139  81 182]\n",
      "  [146  88 190]]\n",
      "\n",
      " [[158 112 198]\n",
      "  [148  91 160]\n",
      "  [135  68 124]\n",
      "  ...\n",
      "  [136  84 187]\n",
      "  [148  95 202]\n",
      "  [154 100 204]]]\n",
      "(500, 500, 3)\n",
      "[[[138  83 180]\n",
      "  [147  93 192]\n",
      "  [157  88 183]\n",
      "  ...\n",
      "  [211 159 226]\n",
      "  [209 165 237]\n",
      "  [207 170 246]]\n",
      "\n",
      " [[138  77 173]\n",
      "  [145  90 186]\n",
      "  [154  87 184]\n",
      "  ...\n",
      "  [224 179 235]\n",
      "  [224 186 244]\n",
      "  [223 193 251]]\n",
      "\n",
      " [[138  74 170]\n",
      "  [144  89 182]\n",
      "  [152  87 184]\n",
      "  ...\n",
      "  [234 195 242]\n",
      "  [235 200 245]\n",
      "  [235 204 248]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[221 195 236]\n",
      "  [235 199 224]\n",
      "  [221 177 205]\n",
      "  ...\n",
      "  [174 123 184]\n",
      "  [180 126 201]\n",
      "  [190 132 220]]\n",
      "\n",
      " [[225 196 240]\n",
      "  [238 197 217]\n",
      "  [220 170 199]\n",
      "  ...\n",
      "  [173 127 186]\n",
      "  [177 125 195]\n",
      "  [186 124 209]]\n",
      "\n",
      " [[209 173 222]\n",
      "  [211 179 217]\n",
      "  [214 177 203]\n",
      "  ...\n",
      "  [171 106 169]\n",
      "  [170 111 186]\n",
      "  [188 125 206]]]\n",
      "(500, 500, 3)\n",
      "[[[200 154 223]\n",
      "  [204 168 224]\n",
      "  [209 184 225]\n",
      "  ...\n",
      "  [144  75 167]\n",
      "  [153  90 187]\n",
      "  [160  99 191]]\n",
      "\n",
      " [[199 146 220]\n",
      "  [198 153 220]\n",
      "  [200 162 220]\n",
      "  ...\n",
      "  [162  93 192]\n",
      "  [170 108 207]\n",
      "  [174 113 206]]\n",
      "\n",
      " [[198 147 211]\n",
      "  [196 141 210]\n",
      "  [195 140 211]\n",
      "  ...\n",
      "  [177 107 190]\n",
      "  [183 119 199]\n",
      "  [185 121 197]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[180 105 217]\n",
      "  [173  98 200]\n",
      "  [171  97 187]\n",
      "  ...\n",
      "  [ 93  33  70]\n",
      "  [ 85  24  50]\n",
      "  [ 83  20  52]]\n",
      "\n",
      " [[177 102 210]\n",
      "  [173  97 195]\n",
      "  [170  99 186]\n",
      "  ...\n",
      "  [ 92  32  66]\n",
      "  [ 87  27  64]\n",
      "  [ 89  27  74]]\n",
      "\n",
      " [[165 100 199]\n",
      "  [161  92 185]\n",
      "  [159  91 172]\n",
      "  ...\n",
      "  [ 90  30  69]\n",
      "  [ 88  29  80]\n",
      "  [ 94  35  94]]]\n",
      "(500, 500, 3)\n",
      "[[[138  83 180]\n",
      "  [147  93 192]\n",
      "  [157  88 183]\n",
      "  ...\n",
      "  [211 159 226]\n",
      "  [209 165 237]\n",
      "  [207 170 246]]\n",
      "\n",
      " [[138  77 173]\n",
      "  [145  90 186]\n",
      "  [154  87 184]\n",
      "  ...\n",
      "  [224 179 235]\n",
      "  [224 186 244]\n",
      "  [223 193 251]]\n",
      "\n",
      " [[138  74 170]\n",
      "  [144  89 182]\n",
      "  [152  87 184]\n",
      "  ...\n",
      "  [234 195 242]\n",
      "  [235 200 245]\n",
      "  [235 204 248]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[221 195 236]\n",
      "  [235 199 224]\n",
      "  [221 177 205]\n",
      "  ...\n",
      "  [174 123 184]\n",
      "  [180 126 201]\n",
      "  [190 132 220]]\n",
      "\n",
      " [[225 196 240]\n",
      "  [238 197 217]\n",
      "  [220 170 199]\n",
      "  ...\n",
      "  [173 127 186]\n",
      "  [177 125 195]\n",
      "  [186 124 209]]\n",
      "\n",
      " [[209 173 222]\n",
      "  [211 179 217]\n",
      "  [214 177 203]\n",
      "  ...\n",
      "  [171 106 169]\n",
      "  [170 111 186]\n",
      "  [188 125 206]]]\n",
      "(500, 500, 3)\n",
      "[[[200 154 223]\n",
      "  [204 168 224]\n",
      "  [209 184 225]\n",
      "  ...\n",
      "  [144  75 167]\n",
      "  [153  90 187]\n",
      "  [160  99 191]]\n",
      "\n",
      " [[199 146 220]\n",
      "  [198 153 220]\n",
      "  [200 162 220]\n",
      "  ...\n",
      "  [162  93 192]\n",
      "  [170 108 207]\n",
      "  [174 113 206]]\n",
      "\n",
      " [[198 147 211]\n",
      "  [196 141 210]\n",
      "  [195 140 211]\n",
      "  ...\n",
      "  [177 107 190]\n",
      "  [183 119 199]\n",
      "  [185 121 197]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[180 105 217]\n",
      "  [173  98 200]\n",
      "  [171  97 187]\n",
      "  ...\n",
      "  [ 93  33  70]\n",
      "  [ 85  24  50]\n",
      "  [ 83  20  52]]\n",
      "\n",
      " [[177 102 210]\n",
      "  [173  97 195]\n",
      "  [170  99 186]\n",
      "  ...\n",
      "  [ 92  32  66]\n",
      "  [ 87  27  64]\n",
      "  [ 89  27  74]]\n",
      "\n",
      " [[165 100 199]\n",
      "  [161  92 185]\n",
      "  [159  91 172]\n",
      "  ...\n",
      "  [ 90  30  69]\n",
      "  [ 88  29  80]\n",
      "  [ 94  35  94]]]\n",
      "(500, 500, 3)\n",
      "[[[185 165 211]\n",
      "  [205 197 234]\n",
      "  [211 195 236]\n",
      "  ...\n",
      "  [178 150 212]\n",
      "  [178 147 216]\n",
      "  [167 136 203]]\n",
      "\n",
      " [[182 160 204]\n",
      "  [191 178 210]\n",
      "  [209 190 228]\n",
      "  ...\n",
      "  [174 146 210]\n",
      "  [172 140 210]\n",
      "  [159 127 194]]\n",
      "\n",
      " [[180 155 197]\n",
      "  [182 162 193]\n",
      "  [202 176 212]\n",
      "  ...\n",
      "  [169 138 202]\n",
      "  [174 140 208]\n",
      "  [181 147 214]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[236 218 241]\n",
      "  [218 200 223]\n",
      "  [199 181 204]\n",
      "  ...\n",
      "  [233 215 238]\n",
      "  [251 231 248]\n",
      "  [230 202 244]]\n",
      "\n",
      " [[242 224 247]\n",
      "  [228 210 233]\n",
      "  [212 193 215]\n",
      "  ...\n",
      "  [251 246 235]\n",
      "  [241 228 229]\n",
      "  [199 171 218]]\n",
      "\n",
      " [[242 226 249]\n",
      "  [229 210 231]\n",
      "  [218 197 218]\n",
      "  ...\n",
      "  [243 233 235]\n",
      "  [210 190 212]\n",
      "  [174 145 199]]]\n",
      "(500, 500, 3)\n",
      "[[[171 126 193]\n",
      "  [155 117 195]\n",
      "  [148 107 191]\n",
      "  ...\n",
      "  [157 111 184]\n",
      "  [159 114 183]\n",
      "  [169 125 191]]\n",
      "\n",
      " [[166 123 187]\n",
      "  [153 115 183]\n",
      "  [150 110 190]\n",
      "  ...\n",
      "  [162 119 191]\n",
      "  [164 121 192]\n",
      "  [174 134 202]]\n",
      "\n",
      " [[156 100 176]\n",
      "  [151 102 183]\n",
      "  [156 111 198]\n",
      "  ...\n",
      "  [169 132 204]\n",
      "  [170 132 208]\n",
      "  [177 144 217]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[202 151 205]\n",
      "  [203 152 197]\n",
      "  [192 137 177]\n",
      "  ...\n",
      "  [176 131 215]\n",
      "  [171 130 199]\n",
      "  [159 111 147]]\n",
      "\n",
      " [[179 129 189]\n",
      "  [173 122 188]\n",
      "  [153 110 174]\n",
      "  ...\n",
      "  [176 134 212]\n",
      "  [179 134 205]\n",
      "  [170 121 174]]\n",
      "\n",
      " [[156 102 161]\n",
      "  [147  94 160]\n",
      "  [131  91 158]\n",
      "  ...\n",
      "  [176 128 198]\n",
      "  [179 130 200]\n",
      "  [174 125 206]]]\n",
      "(500, 500, 3)\n",
      "[[[126  67 109]\n",
      "  [130  68 105]\n",
      "  [137  73 111]\n",
      "  ...\n",
      "  [184 144 225]\n",
      "  [181 143 228]\n",
      "  [176 136 212]]\n",
      "\n",
      " [[131  66 105]\n",
      "  [135  69 103]\n",
      "  [145  80 117]\n",
      "  ...\n",
      "  [185 143 221]\n",
      "  [178 140 221]\n",
      "  [170 132 198]]\n",
      "\n",
      " [[142  79 117]\n",
      "  [149  86 120]\n",
      "  [158  99 137]\n",
      "  ...\n",
      "  [178 137 211]\n",
      "  [169 133 218]\n",
      "  [163 130 203]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[193 167 227]\n",
      "  [195 164 232]\n",
      "  [195 159 223]\n",
      "  ...\n",
      "  [165 123 212]\n",
      "  [162 126 214]\n",
      "  [160 124 210]]\n",
      "\n",
      " [[189 153 210]\n",
      "  [193 162 230]\n",
      "  [194 156 224]\n",
      "  ...\n",
      "  [165 121 208]\n",
      "  [162 124 215]\n",
      "  [158 123 214]]\n",
      "\n",
      " [[179 134 191]\n",
      "  [182 148 204]\n",
      "  [183 144 205]\n",
      "  ...\n",
      "  [165 120 205]\n",
      "  [162 125 215]\n",
      "  [161 125 217]]]\n",
      "(500, 500, 3)\n",
      "[[[169 116 192]\n",
      "  [164 122 192]\n",
      "  [177 148 204]\n",
      "  ...\n",
      "  [186 149 209]\n",
      "  [164 115 168]\n",
      "  [137  91 147]]\n",
      "\n",
      " [[173 126 208]\n",
      "  [169 127 204]\n",
      "  [179 147 211]\n",
      "  ...\n",
      "  [167 130 201]\n",
      "  [144 105 173]\n",
      "  [122  87 151]]\n",
      "\n",
      " [[173 136 214]\n",
      "  [171 133 209]\n",
      "  [178 143 216]\n",
      "  ...\n",
      "  [159 118 190]\n",
      "  [139 103 170]\n",
      "  [128  92 150]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[187 125 178]\n",
      "  [181 111 156]\n",
      "  [191 135 176]\n",
      "  ...\n",
      "  [174 126 165]\n",
      "  [169  98 125]\n",
      "  [154  88 130]]\n",
      "\n",
      " [[145  90 171]\n",
      "  [142  69 138]\n",
      "  [166 102 159]\n",
      "  ...\n",
      "  [172 117 159]\n",
      "  [169  96 130]\n",
      "  [157  90 133]]\n",
      "\n",
      " [[128  93 189]\n",
      "  [125  72 163]\n",
      "  [154 101 185]\n",
      "  ...\n",
      "  [167 119 155]\n",
      "  [158  91 115]\n",
      "  [152  82 100]]]\n",
      "(500, 500, 3)\n",
      "[[[172 151 221]\n",
      "  [179 144 206]\n",
      "  [179 134 204]\n",
      "  ...\n",
      "  [117  61 123]\n",
      "  [120  65 117]\n",
      "  [126  62 131]]\n",
      "\n",
      " [[173 139 214]\n",
      "  [171 123 193]\n",
      "  [169 116 190]\n",
      "  ...\n",
      "  [122  63 123]\n",
      "  [119  60 124]\n",
      "  [115  58 144]]\n",
      "\n",
      " [[170 110 190]\n",
      "  [165 104 180]\n",
      "  [161 111 189]\n",
      "  ...\n",
      "  [122  62 129]\n",
      "  [121  60 127]\n",
      "  [117  68 153]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[155 119 187]\n",
      "  [154 114 179]\n",
      "  [152 109 184]\n",
      "  ...\n",
      "  [141  97 171]\n",
      "  [140  90 163]\n",
      "  [131  87 169]]\n",
      "\n",
      " [[139  98 179]\n",
      "  [144  99 183]\n",
      "  [144  97 179]\n",
      "  ...\n",
      "  [153  98 174]\n",
      "  [148  87 169]\n",
      "  [136  95 173]]\n",
      "\n",
      " [[122  71 154]\n",
      "  [124  76 161]\n",
      "  [127  83 161]\n",
      "  ...\n",
      "  [165 115 213]\n",
      "  [170  96 194]\n",
      "  [154 111 189]]]\n",
      "(500, 500, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[163 120 185]\n",
      "  [158 120 183]\n",
      "  [153 120 183]\n",
      "  ...\n",
      "  [101  46  79]\n",
      "  [113  65 108]\n",
      "  [136  93 148]]\n",
      "\n",
      " [[169 121 181]\n",
      "  [165 121 180]\n",
      "  [161 121 179]\n",
      "  ...\n",
      "  [ 94  42  76]\n",
      "  [109  61 107]\n",
      "  [132  88 147]]\n",
      "\n",
      " [[173 124 185]\n",
      "  [172 124 183]\n",
      "  [169 124 183]\n",
      "  ...\n",
      "  [ 92  43  78]\n",
      "  [103  56 105]\n",
      "  [118  73 136]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[221 199 215]\n",
      "  [217 195 216]\n",
      "  [206 175 215]\n",
      "  ...\n",
      "  [148  99 161]\n",
      "  [150  98 160]\n",
      "  [152 103 173]]\n",
      "\n",
      " [[219 196 210]\n",
      "  [212 186 211]\n",
      "  [206 166 213]\n",
      "  ...\n",
      "  [154 107 177]\n",
      "  [154 106 174]\n",
      "  [152 104 169]]\n",
      "\n",
      " [[217 197 214]\n",
      "  [209 183 211]\n",
      "  [203 161 207]\n",
      "  ...\n",
      "  [153 120 179]\n",
      "  [151 111 172]\n",
      "  [150 101 165]]]\n",
      "(500, 500, 3)\n",
      "[[[220 209 250]\n",
      "  [200 182 240]\n",
      "  [179 138 196]\n",
      "  ...\n",
      "  [134  78 134]\n",
      "  [132  87 140]\n",
      "  [127  75 115]]\n",
      "\n",
      " [[212 187 239]\n",
      "  [182 145 218]\n",
      "  [156 102 168]\n",
      "  ...\n",
      "  [132  77 141]\n",
      "  [129  81 136]\n",
      "  [124  66 104]]\n",
      "\n",
      " [[203 161 220]\n",
      "  [173 116 184]\n",
      "  [149  83 145]\n",
      "  ...\n",
      "  [137  74 144]\n",
      "  [133  74 137]\n",
      "  [128  56 103]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[172 120 209]\n",
      "  [164 107 205]\n",
      "  [161 106 212]\n",
      "  ...\n",
      "  [246 242 241]\n",
      "  [246 239 242]\n",
      "  [246 237 243]]\n",
      "\n",
      " [[174 117 211]\n",
      "  [159  95 191]\n",
      "  [150  87 186]\n",
      "  ...\n",
      "  [244 241 244]\n",
      "  [243 236 243]\n",
      "  [244 235 243]]\n",
      "\n",
      " [[176 124 223]\n",
      "  [156  92 186]\n",
      "  [142  75 165]\n",
      "  ...\n",
      "  [239 237 249]\n",
      "  [236 231 247]\n",
      "  [236 230 245]]]\n",
      "(500, 500, 3)\n",
      "[[[140  72 153]\n",
      "  [133  65 153]\n",
      "  [124  56 149]\n",
      "  ...\n",
      "  [141  65 140]\n",
      "  [144  66 145]\n",
      "  [138  68 165]]\n",
      "\n",
      " [[151  90 183]\n",
      "  [142  77 169]\n",
      "  [129  61 153]\n",
      "  ...\n",
      "  [142  66 140]\n",
      "  [146  68 147]\n",
      "  [143  77 163]]\n",
      "\n",
      " [[151  96 195]\n",
      "  [141  81 170]\n",
      "  [129  65 146]\n",
      "  ...\n",
      "  [141  72 155]\n",
      "  [145  75 166]\n",
      "  [148  95 182]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[196 158 191]\n",
      "  [194 155 193]\n",
      "  [194 154 196]\n",
      "  ...\n",
      "  [136  77 179]\n",
      "  [136  81 193]\n",
      "  [144 102 212]]\n",
      "\n",
      " [[198 161 196]\n",
      "  [195 158 198]\n",
      "  [193 156 203]\n",
      "  ...\n",
      "  [137  75 174]\n",
      "  [137  75 184]\n",
      "  [147 104 207]]\n",
      "\n",
      " [[197 158 193]\n",
      "  [190 150 192]\n",
      "  [185 144 195]\n",
      "  ...\n",
      "  [143  81 182]\n",
      "  [142  77 184]\n",
      "  [148 100 197]]]\n",
      "(500, 500, 3)\n",
      "[[[167 122 183]\n",
      "  [188 144 208]\n",
      "  [180 137 206]\n",
      "  ...\n",
      "  [174 117 172]\n",
      "  [186 131 185]\n",
      "  [168 114 167]]\n",
      "\n",
      " [[181 120 191]\n",
      "  [195 136 209]\n",
      "  [193 137 217]\n",
      "  ...\n",
      "  [158 101 149]\n",
      "  [162 106 156]\n",
      "  [153  96 147]]\n",
      "\n",
      " [[179 111 184]\n",
      "  [189 122 198]\n",
      "  [195 132 215]\n",
      "  ...\n",
      "  [138  82 126]\n",
      "  [142  83 132]\n",
      "  [145  86 136]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[162 105 155]\n",
      "  [168 113 164]\n",
      "  [182 130 184]\n",
      "  ...\n",
      "  [127  63 123]\n",
      "  [121  57 111]\n",
      "  [120  56 108]]\n",
      "\n",
      " [[167 102 167]\n",
      "  [160  97 165]\n",
      "  [166 108 180]\n",
      "  ...\n",
      "  [128  65 122]\n",
      "  [120  63 100]\n",
      "  [116  62  91]]\n",
      "\n",
      " [[174 106 177]\n",
      "  [156  90 163]\n",
      "  [152  90 168]\n",
      "  ...\n",
      "  [141  76 138]\n",
      "  [119  62 100]\n",
      "  [112  59  87]]]\n",
      "(500, 500, 3)\n",
      "[[[175 140 180]\n",
      "  [165 130 170]\n",
      "  [154 113 164]\n",
      "  ...\n",
      "  [211 187 235]\n",
      "  [197 174 228]\n",
      "  [169 146 200]]\n",
      "\n",
      " [[177 141 183]\n",
      "  [156 120 162]\n",
      "  [154 111 162]\n",
      "  ...\n",
      "  [205 176 232]\n",
      "  [188 160 220]\n",
      "  [159 131 191]]\n",
      "\n",
      " [[180 141 186]\n",
      "  [151 112 157]\n",
      "  [152 110 158]\n",
      "  ...\n",
      "  [196 161 225]\n",
      "  [179 145 209]\n",
      "  [154 120 184]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[163 123 178]\n",
      "  [160 120 175]\n",
      "  [156 114 169]\n",
      "  ...\n",
      "  [192 163 209]\n",
      "  [202 167 224]\n",
      "  [191 156 213]]\n",
      "\n",
      " [[171 132 188]\n",
      "  [164 125 181]\n",
      "  [161 116 172]\n",
      "  ...\n",
      "  [199 173 226]\n",
      "  [211 178 245]\n",
      "  [191 158 225]]\n",
      "\n",
      " [[186 149 205]\n",
      "  [168 131 187]\n",
      "  [170 122 180]\n",
      "  ...\n",
      "  [215 192 247]\n",
      "  [198 169 242]\n",
      "  [166 137 210]]]\n",
      "(500, 500, 3)\n",
      "[[[162 124 199]\n",
      "  [169 130 205]\n",
      "  [177 137 211]\n",
      "  ...\n",
      "  [205 177 237]\n",
      "  [192 165 212]\n",
      "  [183 141 227]]\n",
      "\n",
      " [[174 139 213]\n",
      "  [183 145 221]\n",
      "  [169 129 206]\n",
      "  ...\n",
      "  [194 158 226]\n",
      "  [194 159 222]\n",
      "  [174 134 210]]\n",
      "\n",
      " [[184 153 222]\n",
      "  [191 156 232]\n",
      "  [184 146 225]\n",
      "  ...\n",
      "  [183 140 219]\n",
      "  [196 154 232]\n",
      "  [178 139 208]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[120  77 156]\n",
      "  [136  88 173]\n",
      "  [154 102 188]\n",
      "  ...\n",
      "  [128  84 143]\n",
      "  [176 118 185]\n",
      "  [161 127 186]]\n",
      "\n",
      " [[125  76 133]\n",
      "  [140  83 145]\n",
      "  [162 102 167]\n",
      "  ...\n",
      "  [122  77 141]\n",
      "  [164 112 196]\n",
      "  [155 113 181]]\n",
      "\n",
      " [[149 101 161]\n",
      "  [152 113 169]\n",
      "  [149 114 167]\n",
      "  ...\n",
      "  [111  67 126]\n",
      "  [132  84 164]\n",
      "  [140  93 174]]]\n",
      "(500, 500, 3)\n",
      "[[[136  79 130]\n",
      "  [134  78 127]\n",
      "  [133  77 126]\n",
      "  ...\n",
      "  [177 143 208]\n",
      "  [194 160 225]\n",
      "  [193 159 224]]\n",
      "\n",
      " [[136  78 132]\n",
      "  [132  76 127]\n",
      "  [130  74 123]\n",
      "  ...\n",
      "  [173 139 204]\n",
      "  [184 149 216]\n",
      "  [185 151 216]]\n",
      "\n",
      " [[134  77 132]\n",
      "  [129  75 128]\n",
      "  [128  72 123]\n",
      "  ...\n",
      "  [160 125 192]\n",
      "  [163 127 197]\n",
      "  [170 135 202]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[142 103 188]\n",
      "  [129  91 173]\n",
      "  [138  98 180]\n",
      "  ...\n",
      "  [180 152 221]\n",
      "  [180 149 218]\n",
      "  [184 153 220]]\n",
      "\n",
      " [[141 103 185]\n",
      "  [135  97 179]\n",
      "  [153 114 194]\n",
      "  ...\n",
      "  [176 148 217]\n",
      "  [179 148 217]\n",
      "  [186 155 222]]\n",
      "\n",
      " [[147 109 191]\n",
      "  [147 110 190]\n",
      "  [169 130 210]\n",
      "  ...\n",
      "  [169 141 210]\n",
      "  [175 144 213]\n",
      "  [184 153 220]]]\n",
      "(500, 500, 3)\n",
      "[[[169 155 189]\n",
      "  [223 209 243]\n",
      "  [232 213 252]\n",
      "  ...\n",
      "  [149 118 179]\n",
      "  [160 136 190]\n",
      "  [181 157 211]]\n",
      "\n",
      " [[164 139 183]\n",
      "  [210 185 229]\n",
      "  [208 184 226]\n",
      "  ...\n",
      "  [153 122 191]\n",
      "  [186 168 209]\n",
      "  [214 196 237]]\n",
      "\n",
      " [[162 126 180]\n",
      "  [195 159 213]\n",
      "  [180 151 196]\n",
      "  ...\n",
      "  [166 131 211]\n",
      "  [214 200 228]\n",
      "  [242 228 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[157  99 180]\n",
      "  [155  97 178]\n",
      "  [161 119 196]\n",
      "  ...\n",
      "  [194 166 225]\n",
      "  [185 158 222]\n",
      "  [188 161 225]]\n",
      "\n",
      " [[162 107 192]\n",
      "  [144  89 174]\n",
      "  [158 112 189]\n",
      "  ...\n",
      "  [181 148 215]\n",
      "  [194 165 234]\n",
      "  [204 175 244]]\n",
      "\n",
      " [[153  97 186]\n",
      "  [138  82 171]\n",
      "  [141 109 186]\n",
      "  ...\n",
      "  [162 124 200]\n",
      "  [193 164 237]\n",
      "  [210 181 254]]]\n",
      "(500, 500, 3)\n",
      "[[[192 141 222]\n",
      "  [185 133 215]\n",
      "  [179 124 206]\n",
      "  ...\n",
      "  [165 117 186]\n",
      "  [160 107 185]\n",
      "  [166 111 191]]\n",
      "\n",
      " [[181 120 198]\n",
      "  [188 121 200]\n",
      "  [186 116 197]\n",
      "  ...\n",
      "  [151  98 180]\n",
      "  [168 109 185]\n",
      "  [185 127 196]]\n",
      "\n",
      " [[172 105 181]\n",
      "  [187 113 189]\n",
      "  [190 114 193]\n",
      "  ...\n",
      "  [151  92 180]\n",
      "  [172 107 182]\n",
      "  [189 125 193]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[201 153 229]\n",
      "  [208 155 237]\n",
      "  [197 140 225]\n",
      "  ...\n",
      "  [169 111 169]\n",
      "  [169 116 193]\n",
      "  [183 132 219]]\n",
      "\n",
      " [[187 131 201]\n",
      "  [198 137 214]\n",
      "  [191 126 209]\n",
      "  ...\n",
      "  [159  97 160]\n",
      "  [173 118 196]\n",
      "  [192 142 226]]\n",
      "\n",
      " [[164 103 173]\n",
      "  [183 117 192]\n",
      "  [194 127 204]\n",
      "  ...\n",
      "  [163 101 168]\n",
      "  [171 110 186]\n",
      "  [186 128 206]]]\n",
      "(500, 500, 3)\n",
      "[[[107  45  98]\n",
      "  [ 99  40 100]\n",
      "  [ 93  36 102]\n",
      "  ...\n",
      "  [108  57 131]\n",
      "  [117  55 134]\n",
      "  [129  63 164]]\n",
      "\n",
      " [[103  44  95]\n",
      "  [ 93  39  93]\n",
      "  [ 87  34  99]\n",
      "  ...\n",
      "  [109  58 139]\n",
      "  [120  58 140]\n",
      "  [125  61 155]]\n",
      "\n",
      " [[ 97  45  98]\n",
      "  [ 90  41  91]\n",
      "  [ 86  37  97]\n",
      "  ...\n",
      "  [115  64 146]\n",
      "  [122  66 149]\n",
      "  [118  66 157]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 74  34  73]\n",
      "  [ 78  33  79]\n",
      "  [ 81  32  93]\n",
      "  ...\n",
      "  [122  65 135]\n",
      "  [124  73 140]\n",
      "  [121  73 164]]\n",
      "\n",
      " [[ 76  36  70]\n",
      "  [ 80  32  69]\n",
      "  [ 83  27  78]\n",
      "  ...\n",
      "  [132  77 163]\n",
      "  [133  85 160]\n",
      "  [123  75 162]]\n",
      "\n",
      " [[ 79  37  75]\n",
      "  [ 84  29  67]\n",
      "  [ 87  21  72]\n",
      "  ...\n",
      "  [133  86 192]\n",
      "  [132  93 179]\n",
      "  [133  83 167]]]\n",
      "(500, 500, 3)\n",
      "[[[173 113 174]\n",
      "  [178 121 178]\n",
      "  [173 123 190]\n",
      "  ...\n",
      "  [195 154 212]\n",
      "  [176 133 177]\n",
      "  [154 103 132]]\n",
      "\n",
      " [[179 130 186]\n",
      "  [180 118 179]\n",
      "  [173 120 186]\n",
      "  ...\n",
      "  [190 147 196]\n",
      "  [162 114 150]\n",
      "  [130  75  95]]\n",
      "\n",
      " [[181 135 188]\n",
      "  [180 121 178]\n",
      "  [172 118 179]\n",
      "  ...\n",
      "  [180 145 193]\n",
      "  [156 107 142]\n",
      "  [127  67  90]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[151  95 158]\n",
      "  [153 128 191]\n",
      "  [141 112 172]\n",
      "  ...\n",
      "  [ 89  22  58]\n",
      "  [ 90  29  58]\n",
      "  [ 94  36  55]]\n",
      "\n",
      " [[152  93 163]\n",
      "  [152 117 186]\n",
      "  [142 116 173]\n",
      "  ...\n",
      "  [105  38  69]\n",
      "  [ 99  36  57]\n",
      "  [ 97  36  56]]\n",
      "\n",
      " [[153  97 172]\n",
      "  [151 102 174]\n",
      "  [143 113 168]\n",
      "  ...\n",
      "  [126  61  95]\n",
      "  [110  47  66]\n",
      "  [ 99  36  69]]]\n",
      "(500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Train/image') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Resize_images('/home/hp/data/Train/image/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "(5, 256, 256, 3)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Extracting 5 patches of size 256X256 from each image\n",
    "\n",
    "path = '/home/hp/data/Train/image1/'\n",
    "path1 = '/home/hp/data/Train/label1/'\n",
    "list = os.listdir('/home/hp/data/Train/image1') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "patch_size = (256, 256)\n",
    "\n",
    "k=1\n",
    "for i in range(1, size+1):\n",
    "    img = cv2.imread(path+str(i)+'.png')\n",
    "    img1 = cv2.imread(path1+str(i)+'.png')\n",
    "    data = extract_patches_2d(img, patch_size, max_patches=5,random_state=1)\n",
    "    data1 = extract_patches_2d(img1, patch_size, max_patches=5,random_state=1)\n",
    "    print(data.shape)\n",
    "    print(data1.shape)\n",
    "    data = np.array(data) \n",
    "    data1 = np.array(data1) \n",
    "    print(data.shape)\n",
    "    print(data1.shape)\n",
    "    print('-'*30)\n",
    "    #print(data.shape)\n",
    "    #print(data1.shape)\n",
    "    for j in range(data.shape[0]):\n",
    "        img = data[j]\n",
    "        img1 = data1[j]\n",
    "        img = array_to_img(img)\n",
    "        img1 = array_to_img(img1)\n",
    "        img.save(\"/home/hp/patch_image/%d.png\"%(k))\n",
    "        img1.save(\"/home/hp/patch_label/%d.png\"%(k))\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=0.2,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "#augmentation\n",
    "\n",
    "seed = 1\n",
    "\n",
    "path = '/home/hp/patch_image/'\n",
    "path2 = '/home/hp/patch_label/'\n",
    "list = os.listdir('/home/hp/patch_image/') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "for i in range(1, size+1):\n",
    "        img = load_img(path+str(i)+'.png')   \n",
    "        x = img_to_array(img)  \n",
    "        x = x.reshape((1,) + x.shape)  \n",
    "        \n",
    "        img2 = load_img(path2+str(i)+'.png')  \n",
    "        y = img_to_array(img2)  \n",
    "        y = y.reshape((1,) + y.shape)  \n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        j = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='/home/hp/data/Train/image2', save_format='png', seed = seed):\n",
    "            j += 1\n",
    "            if j > 30:\n",
    "                break  \n",
    "                \n",
    "        j = 0\n",
    "        for batch in datagen.flow(y, batch_size=1,\n",
    "                          save_to_dir='/home/hp/data/Train/label2', save_format='png', seed = seed):\n",
    "            j += 1\n",
    "            if j > 30:\n",
    "                break  \n",
    "        \n",
    "        seed +=2293\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the files in a folder\n",
    "\n",
    "path = '/home/hp/data/Train/image2'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "\n",
    "for file in files:\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, str(i)+'.png'))\n",
    "    i = i+1\n",
    "    \n",
    "path = '/home/hp/data/Train/label2'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "\n",
    "for file in files:\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, str(i)+'.png'))\n",
    "    i = i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3115\n",
      "[[[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0 255 255]\n",
      "  [  0   0   0 ...   0   0 255]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [255 255 255 ...   0   0   0]\n",
      "  [255 255 255 ...   0   0   0]\n",
      "  [255 255 255 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [255   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]]\n",
      "(3115, 256, 256)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Conversion of masks to numpy array\n",
    "\n",
    "def Conv_to_NumArr(source, size):\n",
    "    temp_arr = []\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY)\n",
    "        temp_arr.append(thresh)\n",
    "        #print(type(img))\n",
    "    temp = np.array(temp_arr)#https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array\n",
    "    return temp \n",
    "\n",
    "\n",
    "list = os.listdir('/home/hp/data/Train/label2') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Train_data_mask = Conv_to_NumArr('/home/hp/data/Train/label2/', number_files)\n",
    "print(Train_data_mask)\n",
    "print(Train_data_mask.shape)\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3115\n",
      "[[[ 87  83  82 ...  78  78  78]\n",
      "  [ 87  83  82 ...  78  78  78]\n",
      "  [ 87  83  82 ...  78  78  78]\n",
      "  ...\n",
      "  [119 111 103 ...  95  95  95]\n",
      "  [106 106 106 ...  94  94  94]\n",
      "  [ 90 100 108 ...  97  97  97]]\n",
      "\n",
      " [[143 172 177 ...  84  88  98]\n",
      "  [141 170 184 ... 109 113 110]\n",
      "  [138 160 181 ... 133 138 130]\n",
      "  ...\n",
      "  [156 142 134 ... 131 134 150]\n",
      "  [136 130 127 ... 131 134 150]\n",
      "  [136 130 127 ... 131 134 150]]\n",
      "\n",
      " [[127 127 127 ...  89  77  68]\n",
      "  [120 120 120 ... 112  95  78]\n",
      "  [109 109 109 ... 128 116  98]\n",
      "  ...\n",
      "  [130 130 130 ... 105 102  96]\n",
      "  [130 130 130 ... 105 102  96]\n",
      "  [130 130 130 ... 105 102  96]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[197 200 186 ... 112 112 112]\n",
      "  [188 199 190 ... 123 123 123]\n",
      "  [158 179 175 ... 110 110 110]\n",
      "  ...\n",
      "  [106 105 122 ... 105 105 105]\n",
      "  [114 105 101 ... 105 105 105]\n",
      "  [108 106 101 ... 129 129 129]]\n",
      "\n",
      " [[101 102 111 ...  68  68  68]\n",
      "  [101 102 111 ...  68  68  68]\n",
      "  [101 102 111 ...  68  68  68]\n",
      "  ...\n",
      "  [ 77  89  88 ...  97  97  97]\n",
      "  [ 70  89  91 ...  97  97  97]\n",
      "  [ 72  86  88 ...  97  97  97]]\n",
      "\n",
      " [[152 157 164 ... 140 140 140]\n",
      "  [170 173 169 ... 136 136 136]\n",
      "  [174 178 176 ... 133 133 133]\n",
      "  ...\n",
      "  [142 141 141 ... 122 122 122]\n",
      "  [134 134 135 ... 128 128 128]\n",
      "  [130 131 132 ... 128 128 128]]]\n",
      "(3115, 256, 256)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Conversion of images to numpy array\n",
    "\n",
    "def Conv_to_NumArr(source, size):\n",
    "    temp_arr = []\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #ret,thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY)\n",
    "        temp_arr.append(img)\n",
    "        #print(type(img))\n",
    "    temp = np.array(temp_arr)#https://stackoverflow.com/questions/9775297/append-a-numpy-array-to-a-numpy-array\n",
    "    return temp \n",
    "\n",
    "list = os.listdir('/home/hp/data/Train/image2') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Train_data_image = Conv_to_NumArr('/home/hp/data/Train/image2/', number_files)\n",
    "print(Train_data_image)\n",
    "print(Train_data_image.shape)\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the test images\n",
    "\n",
    "def Resize_test(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.resize(img,(256, 256))\n",
    "        cv2.imwrite(\"/home/hp/data/Test/image1/%d.png\"%(j),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Test/image') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Resize_test('/home/hp/data/Test/image/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce binary masks for testing, resize all the masks to 256X256 \n",
    "def Test_to_BinLabel(source, size):\n",
    "    for j in range(1,size+1): \n",
    "        img = cv2.imread(source+str(j)+'.png')\n",
    "        #img1=img[:,:,2]\n",
    "        #img2=(img1!=0)\n",
    "        #plt.imsave(source+str(j)+'.png', ~img[:,:,2], cmap=plt.cm.gray)#grey inverse\n",
    "        #img3 = cv2.imread(source+str(j)+'.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        #cv2.imwrite(source+str(j)+'.png', thresh)#final mask\n",
    "        #img4 = cv2.imread(source+str(j)+'.png')\n",
    "        img4 = cv2.resize(img,(256, 256))\n",
    "        ret,thresh = cv2.threshold(img4,0,255,cv2.THRESH_BINARY)\n",
    "        print(thresh)\n",
    "        print(thresh.shape)\n",
    "        print('_'*30)\n",
    "        cv2.imwrite(\"/home/hp/data/Test/label1/%d.png\"%(j),thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[  0   0   0 ... 255 255   0]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " ...\n",
      " [  0 255 255 ... 255 255 255]\n",
      " [  0 255 255 ... 255 255 255]\n",
      " [  0 255 255 ... 255 255 255]]\n",
      "(256, 256)\n",
      "______________________________\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(256, 256)\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Test/label') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Test_to_BinLabel('/home/hp/data/Test/label/', number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[[199 206 206 ... 218 216 215]\n",
      "  [196 210 210 ... 219 216 213]\n",
      "  [198 205 200 ... 220 215 211]\n",
      "  ...\n",
      "  [120 120 132 ... 122 113 116]\n",
      "  [122 120 134 ... 115 109 109]\n",
      "  [ 87  84  94 ... 110 123 134]]\n",
      "\n",
      " [[164 192 171 ... 149 142 148]\n",
      "  [176 182 171 ... 130 142 156]\n",
      "  [167 166 159 ... 112 124 136]\n",
      "  ...\n",
      "  [216 216 216 ... 191 190 168]\n",
      "  [217 217 216 ... 145 138 126]\n",
      "  [218 218 217 ... 142 144 137]]\n",
      "\n",
      " [[189 209 222 ... 112 109 100]\n",
      "  [195 220 225 ... 102 103  83]\n",
      "  [198 209 205 ... 100  90  63]\n",
      "  ...\n",
      "  [170 153 146 ... 119 125 130]\n",
      "  [158 143 142 ... 131 122 128]\n",
      "  [150 149 153 ... 146 127 123]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[114 137 136 ... 125 108 111]\n",
      "  [117 120 116 ... 113 103 105]\n",
      "  [138 136 126 ... 108 107 106]\n",
      "  ...\n",
      "  [118 161 175 ... 141 153 160]\n",
      "  [ 83 109 150 ... 152 158 170]\n",
      "  [ 60  62  93 ... 164 165 161]]\n",
      "\n",
      " [[115 118 120 ...  80  95  93]\n",
      "  [125 122 121 ...  83  79  86]\n",
      "  [120 116 115 ...  81  78  84]\n",
      "  ...\n",
      "  [164 134  71 ...  70  53  59]\n",
      "  [151 110  64 ...  58  50  53]\n",
      "  [147  95  62 ...  72  48  49]]\n",
      "\n",
      " [[110 114  93 ...  73  56  63]\n",
      "  [123 105 118 ...  74  63  73]\n",
      "  [134 108 132 ...  85  83  83]\n",
      "  ...\n",
      "  [113 176 186 ... 132 150 165]\n",
      "  [115 209 197 ... 145 145 150]\n",
      "  [ 94 154 184 ... 147 130 123]]]\n",
      "(8, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "list = os.listdir('/home/hp/data/Test/image1') # dir is your directory path\n",
    "number_files = len(list)\n",
    "print (number_files)\n",
    "\n",
    "Test_data_image = Conv_to_NumArr('/home/hp/data/Test/image1/', number_files)\n",
    "print(Test_data_image)\n",
    "print(Test_data_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Train_data_image2 ********\n",
      "[[[[-1.1347111 ]\n",
      "   [-1.2238863 ]\n",
      "   [-1.2461799 ]\n",
      "   ...\n",
      "   [-1.3353552 ]\n",
      "   [-1.3353552 ]\n",
      "   [-1.3353552 ]]\n",
      "\n",
      "  [[-1.1347111 ]\n",
      "   [-1.2238863 ]\n",
      "   [-1.2461799 ]\n",
      "   ...\n",
      "   [-1.3353552 ]\n",
      "   [-1.3353552 ]\n",
      "   [-1.3353552 ]]\n",
      "\n",
      "  [[-1.1347111 ]\n",
      "   [-1.2238863 ]\n",
      "   [-1.2461799 ]\n",
      "   ...\n",
      "   [-1.3353552 ]\n",
      "   [-1.3353552 ]\n",
      "   [-1.3353552 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.42131013]\n",
      "   [-0.5996604 ]\n",
      "   [-0.7780106 ]\n",
      "   ...\n",
      "   [-0.9563609 ]\n",
      "   [-0.9563609 ]\n",
      "   [-0.9563609 ]]\n",
      "\n",
      "  [[-0.71112925]\n",
      "   [-0.71112925]\n",
      "   [-0.71112925]\n",
      "   ...\n",
      "   [-0.9786546 ]\n",
      "   [-0.9786546 ]\n",
      "   [-0.9786546 ]]\n",
      "\n",
      "  [[-1.0678297 ]\n",
      "   [-0.84489197]\n",
      "   [-0.6665417 ]\n",
      "   ...\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]]]\n",
      "\n",
      "\n",
      " [[[ 0.11374059]\n",
      "   [ 0.7602602 ]\n",
      "   [ 0.87172914]\n",
      "   ...\n",
      "   [-1.2015924 ]\n",
      "   [-1.1124173 ]\n",
      "   [-0.8894795 ]]\n",
      "\n",
      "  [[ 0.06915303]\n",
      "   [ 0.7156727 ]\n",
      "   [ 1.0277855 ]\n",
      "   ...\n",
      "   [-0.64424795]\n",
      "   [-0.5550728 ]\n",
      "   [-0.62195414]]\n",
      "\n",
      "  [[ 0.0022717 ]\n",
      "   [ 0.49273485]\n",
      "   [ 0.96090424]\n",
      "   ...\n",
      "   [-0.10919721]\n",
      "   [ 0.0022717 ]\n",
      "   [-0.17607854]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.40355974]\n",
      "   [ 0.09144682]\n",
      "   [-0.08690342]\n",
      "   ...\n",
      "   [-0.15378477]\n",
      "   [-0.08690342]\n",
      "   [ 0.26979706]]\n",
      "\n",
      "  [[-0.04231586]\n",
      "   [-0.17607854]\n",
      "   [-0.24295989]\n",
      "   ...\n",
      "   [-0.15378477]\n",
      "   [-0.08690342]\n",
      "   [ 0.26979706]]\n",
      "\n",
      "  [[-0.04231586]\n",
      "   [-0.17607854]\n",
      "   [-0.24295989]\n",
      "   ...\n",
      "   [-0.15378477]\n",
      "   [-0.08690342]\n",
      "   [ 0.26979706]]]\n",
      "\n",
      "\n",
      " [[[-0.24295989]\n",
      "   [-0.24295989]\n",
      "   [-0.24295989]\n",
      "   ...\n",
      "   [-1.0901235 ]\n",
      "   [-1.3576488 ]\n",
      "   [-1.5582929 ]]\n",
      "\n",
      "  [[-0.39901635]\n",
      "   [-0.39901635]\n",
      "   [-0.39901635]\n",
      "   ...\n",
      "   [-0.5773666 ]\n",
      "   [-0.9563609 ]\n",
      "   [-1.3353552 ]]\n",
      "\n",
      "  [[-0.64424795]\n",
      "   [-0.64424795]\n",
      "   [-0.64424795]\n",
      "   ...\n",
      "   [-0.22066611]\n",
      "   [-0.48819146]\n",
      "   [-0.8894795 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.17607854]\n",
      "   [-0.17607854]\n",
      "   [-0.17607854]\n",
      "   ...\n",
      "   [-0.73342305]\n",
      "   [-0.8003044 ]\n",
      "   [-0.9340671 ]]\n",
      "\n",
      "  [[-0.17607854]\n",
      "   [-0.17607854]\n",
      "   [-0.17607854]\n",
      "   ...\n",
      "   [-0.73342305]\n",
      "   [-0.8003044 ]\n",
      "   [-0.9340671 ]]\n",
      "\n",
      "  [[-0.17607854]\n",
      "   [-0.17607854]\n",
      "   [-0.17607854]\n",
      "   ...\n",
      "   [-0.73342305]\n",
      "   [-0.8003044 ]\n",
      "   [-0.9340671 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 1.3176048 ]\n",
      "   [ 1.3844861 ]\n",
      "   [ 1.0723732 ]\n",
      "   ...\n",
      "   [-0.5773666 ]\n",
      "   [-0.5773666 ]\n",
      "   [-0.5773666 ]]\n",
      "\n",
      "  [[ 1.1169606 ]\n",
      "   [ 1.3621923 ]\n",
      "   [ 1.1615483 ]\n",
      "   ...\n",
      "   [-0.332135  ]\n",
      "   [-0.332135  ]\n",
      "   [-0.332135  ]]\n",
      "\n",
      "  [[ 0.4481473 ]\n",
      "   [ 0.9163167 ]\n",
      "   [ 0.8271416 ]\n",
      "   ...\n",
      "   [-0.62195414]\n",
      "   [-0.62195414]\n",
      "   [-0.62195414]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.71112925]\n",
      "   [-0.73342305]\n",
      "   [-0.3544288 ]\n",
      "   ...\n",
      "   [-0.73342305]\n",
      "   [-0.73342305]\n",
      "   [-0.73342305]]\n",
      "\n",
      "  [[-0.53277904]\n",
      "   [-0.73342305]\n",
      "   [-0.82259816]\n",
      "   ...\n",
      "   [-0.73342305]\n",
      "   [-0.73342305]\n",
      "   [-0.73342305]]\n",
      "\n",
      "  [[-0.6665417 ]\n",
      "   [-0.71112925]\n",
      "   [-0.82259816]\n",
      "   ...\n",
      "   [-0.19837232]\n",
      "   [-0.19837232]\n",
      "   [-0.19837232]]]\n",
      "\n",
      "\n",
      " [[[-0.82259816]\n",
      "   [-0.8003044 ]\n",
      "   [-0.5996604 ]\n",
      "   ...\n",
      "   [-1.5582929 ]\n",
      "   [-1.5582929 ]\n",
      "   [-1.5582929 ]]\n",
      "\n",
      "  [[-0.82259816]\n",
      "   [-0.8003044 ]\n",
      "   [-0.5996604 ]\n",
      "   ...\n",
      "   [-1.5582929 ]\n",
      "   [-1.5582929 ]\n",
      "   [-1.5582929 ]]\n",
      "\n",
      "  [[-0.82259816]\n",
      "   [-0.8003044 ]\n",
      "   [-0.5996604 ]\n",
      "   ...\n",
      "   [-1.5582929 ]\n",
      "   [-1.5582929 ]\n",
      "   [-1.5582929 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.3576488 ]\n",
      "   [-1.0901235 ]\n",
      "   [-1.1124173 ]\n",
      "   ...\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]]\n",
      "\n",
      "  [[-1.5137054 ]\n",
      "   [-1.0901235 ]\n",
      "   [-1.0455359 ]\n",
      "   ...\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]]\n",
      "\n",
      "  [[-1.4691178 ]\n",
      "   [-1.1570048 ]\n",
      "   [-1.1124173 ]\n",
      "   ...\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]\n",
      "   [-0.91177326]]]\n",
      "\n",
      "\n",
      " [[[ 0.3143846 ]\n",
      "   [ 0.42585352]\n",
      "   [ 0.58190995]\n",
      "   ...\n",
      "   [ 0.04685926]\n",
      "   [ 0.04685926]\n",
      "   [ 0.04685926]]\n",
      "\n",
      "  [[ 0.7156727 ]\n",
      "   [ 0.78255403]\n",
      "   [ 0.69337887]\n",
      "   ...\n",
      "   [-0.04231586]\n",
      "   [-0.04231586]\n",
      "   [-0.04231586]]\n",
      "\n",
      "  [[ 0.8048478 ]\n",
      "   [ 0.8940229 ]\n",
      "   [ 0.8494353 ]\n",
      "   ...\n",
      "   [-0.10919721]\n",
      "   [-0.10919721]\n",
      "   [-0.10919721]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.09144682]\n",
      "   [ 0.06915303]\n",
      "   [ 0.06915303]\n",
      "   ...\n",
      "   [-0.3544288 ]\n",
      "   [-0.3544288 ]\n",
      "   [-0.3544288 ]]\n",
      "\n",
      "  [[-0.08690342]\n",
      "   [-0.08690342]\n",
      "   [-0.06460965]\n",
      "   ...\n",
      "   [-0.22066611]\n",
      "   [-0.22066611]\n",
      "   [-0.22066611]]\n",
      "\n",
      "  [[-0.17607854]\n",
      "   [-0.15378477]\n",
      "   [-0.13149099]\n",
      "   ...\n",
      "   [-0.22066611]\n",
      "   [-0.22066611]\n",
      "   [-0.22066611]]]]\n",
      "(3115, 256, 256, 1)\n",
      "******* Train_data_mask2 ********\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "(3115, 256, 256, 1)\n",
      "conv1 shape: (?, 256, 256, 32)\n",
      "pool1 shape: (?, 128, 128, 32)\n",
      "conv2 shape: (?, 128, 128, 64)\n",
      "pool2 shape: (?, 64, 64, 64)\n",
      "conv3 shape: (?, 64, 64, 128)\n",
      "conv3 shape: (?, 64, 64, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:53: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:65: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:72: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got unet\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 256, 256, 32) 320         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 128, 128, 32) 0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 128, 128, 64) 18496       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 128)  0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 64, 64, 256)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "merge_10 (Merge)                (None, 64, 64, 256)  0           conv2d_57[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 64, 128)  295040      merge_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 128, 128, 128 0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "merge_11 (Merge)                (None, 128, 128, 128 0           conv2d_55[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 128, 128, 64) 73792       merge_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 256, 256, 64) 0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "merge_12 (Merge)                (None, 256, 256, 64) 0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 256, 256, 32) 18464       merge_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 256, 256, 1)  33          conv2d_68[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,925,025\n",
      "Trainable params: 1,925,025\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hp/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:127: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2492 samples, validate on 623 samples\n",
      "Epoch 1/35\n",
      " - 8400s - loss: 0.2532 - binary_accuracy: 0.8950 - val_loss: 0.1816 - val_binary_accuracy: 0.9252\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.25323, saving model to unet.hdf5\n",
      "Epoch 2/35\n",
      " - 7646s - loss: 0.1447 - binary_accuracy: 0.9403 - val_loss: 0.1099 - val_binary_accuracy: 0.9549\n",
      "\n",
      "Epoch 00002: loss improved from 0.25323 to 0.14465, saving model to unet.hdf5\n",
      "Epoch 3/35\n",
      " - 7637s - loss: 0.0943 - binary_accuracy: 0.9608 - val_loss: 0.0874 - val_binary_accuracy: 0.9635\n",
      "\n",
      "Epoch 00003: loss improved from 0.14465 to 0.09426, saving model to unet.hdf5\n",
      "Epoch 4/35\n",
      " - 7633s - loss: 0.0743 - binary_accuracy: 0.9689 - val_loss: 0.0681 - val_binary_accuracy: 0.9713\n",
      "\n",
      "Epoch 00004: loss improved from 0.09426 to 0.07427, saving model to unet.hdf5\n",
      "Epoch 5/35\n",
      " - 7703s - loss: 0.0618 - binary_accuracy: 0.9740 - val_loss: 0.0614 - val_binary_accuracy: 0.9743\n",
      "\n",
      "Epoch 00005: loss improved from 0.07427 to 0.06181, saving model to unet.hdf5\n",
      "Epoch 6/35\n",
      " - 8438s - loss: 0.0528 - binary_accuracy: 0.9776 - val_loss: 0.0568 - val_binary_accuracy: 0.9763\n",
      "\n",
      "Epoch 00006: loss improved from 0.06181 to 0.05279, saving model to unet.hdf5\n",
      "Epoch 7/35\n",
      " - 8273s - loss: 0.0476 - binary_accuracy: 0.9798 - val_loss: 0.0498 - val_binary_accuracy: 0.9792\n",
      "\n",
      "Epoch 00007: loss improved from 0.05279 to 0.04757, saving model to unet.hdf5\n",
      "Epoch 8/35\n",
      " - 8661s - loss: 0.0440 - binary_accuracy: 0.9813 - val_loss: 0.0448 - val_binary_accuracy: 0.9813\n",
      "\n",
      "Epoch 00008: loss improved from 0.04757 to 0.04405, saving model to unet.hdf5\n",
      "Epoch 9/35\n",
      " - 9134s - loss: 0.0385 - binary_accuracy: 0.9835 - val_loss: 0.0449 - val_binary_accuracy: 0.9814\n",
      "\n",
      "Epoch 00009: loss improved from 0.04405 to 0.03854, saving model to unet.hdf5\n",
      "Epoch 10/35\n",
      " - 10320s - loss: 0.0373 - binary_accuracy: 0.9840 - val_loss: 0.0425 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00010: loss improved from 0.03854 to 0.03730, saving model to unet.hdf5\n",
      "Epoch 11/35\n",
      " - 9498s - loss: 0.0336 - binary_accuracy: 0.9855 - val_loss: 0.0413 - val_binary_accuracy: 0.9830\n",
      "\n",
      "Epoch 00011: loss improved from 0.03730 to 0.03356, saving model to unet.hdf5\n",
      "Epoch 12/35\n",
      " - 7837s - loss: 0.0351 - binary_accuracy: 0.9851 - val_loss: 0.0384 - val_binary_accuracy: 0.9841\n",
      "\n",
      "Epoch 00012: loss did not improve\n",
      "Epoch 13/35\n",
      " - 7828s - loss: 0.0303 - binary_accuracy: 0.9869 - val_loss: 0.0386 - val_binary_accuracy: 0.9840\n",
      "\n",
      "Epoch 00013: loss improved from 0.03356 to 0.03030, saving model to unet.hdf5\n",
      "Epoch 14/35\n",
      " - 7835s - loss: 0.0357 - binary_accuracy: 0.9850 - val_loss: 0.0368 - val_binary_accuracy: 0.9849\n",
      "\n",
      "Epoch 00014: loss did not improve\n",
      "Epoch 15/35\n",
      " - 8028s - loss: 0.0275 - binary_accuracy: 0.9881 - val_loss: 0.0372 - val_binary_accuracy: 0.9847\n",
      "\n",
      "Epoch 00015: loss improved from 0.03030 to 0.02749, saving model to unet.hdf5\n",
      "Epoch 16/35\n",
      " - 7871s - loss: 0.0297 - binary_accuracy: 0.9874 - val_loss: 0.0353 - val_binary_accuracy: 0.9856\n",
      "\n",
      "Epoch 00016: loss did not improve\n",
      "Epoch 17/35\n",
      " - 8625s - loss: 0.0258 - binary_accuracy: 0.9888 - val_loss: 0.0366 - val_binary_accuracy: 0.9853\n",
      "\n",
      "Epoch 00017: loss improved from 0.02749 to 0.02580, saving model to unet.hdf5\n",
      "Epoch 18/35\n",
      " - 8738s - loss: 0.0255 - binary_accuracy: 0.9890 - val_loss: 0.0377 - val_binary_accuracy: 0.9849\n",
      "\n",
      "Epoch 00018: loss improved from 0.02580 to 0.02548, saving model to unet.hdf5\n",
      "Epoch 19/35\n",
      " - 9110s - loss: 0.0254 - binary_accuracy: 0.9891 - val_loss: 0.0354 - val_binary_accuracy: 0.9858\n",
      "\n",
      "Epoch 00019: loss improved from 0.02548 to 0.02538, saving model to unet.hdf5\n",
      "Epoch 20/35\n",
      " - 9461s - loss: 0.0241 - binary_accuracy: 0.9896 - val_loss: 0.0355 - val_binary_accuracy: 0.9858\n",
      "\n",
      "Epoch 00020: loss improved from 0.02538 to 0.02409, saving model to unet.hdf5\n",
      "Epoch 21/35\n",
      " - 9517s - loss: 0.0234 - binary_accuracy: 0.9899 - val_loss: 0.0347 - val_binary_accuracy: 0.9861\n",
      "\n",
      "Epoch 00021: loss improved from 0.02409 to 0.02343, saving model to unet.hdf5\n",
      "Epoch 22/35\n",
      " - 8073s - loss: 0.0241 - binary_accuracy: 0.9896 - val_loss: 0.0358 - val_binary_accuracy: 0.9857\n",
      "\n",
      "Epoch 00022: loss did not improve\n",
      "Epoch 23/35\n",
      " - 7840s - loss: 0.0215 - binary_accuracy: 0.9907 - val_loss: 0.0349 - val_binary_accuracy: 0.9865\n",
      "\n",
      "Epoch 00023: loss improved from 0.02343 to 0.02147, saving model to unet.hdf5\n",
      "Epoch 24/35\n",
      " - 7850s - loss: 0.0214 - binary_accuracy: 0.9908 - val_loss: 0.0343 - val_binary_accuracy: 0.9866\n",
      "\n",
      "Epoch 00024: loss improved from 0.02147 to 0.02137, saving model to unet.hdf5\n",
      "Epoch 25/35\n",
      " - 8204s - loss: 0.0210 - binary_accuracy: 0.9909 - val_loss: 0.0351 - val_binary_accuracy: 0.9866\n",
      "\n",
      "Epoch 00025: loss improved from 0.02137 to 0.02099, saving model to unet.hdf5\n",
      "Epoch 26/35\n",
      " - 7918s - loss: 0.0207 - binary_accuracy: 0.9911 - val_loss: 0.0344 - val_binary_accuracy: 0.9868\n",
      "\n",
      "Epoch 00026: loss improved from 0.02099 to 0.02071, saving model to unet.hdf5\n",
      "Epoch 27/35\n",
      " - 8588s - loss: 0.0198 - binary_accuracy: 0.9914 - val_loss: 0.0348 - val_binary_accuracy: 0.9869\n",
      "\n",
      "Epoch 00027: loss improved from 0.02071 to 0.01983, saving model to unet.hdf5\n",
      "Epoch 28/35\n",
      " - 8945s - loss: 0.0195 - binary_accuracy: 0.9916 - val_loss: 0.0346 - val_binary_accuracy: 0.9867\n",
      "\n",
      "Epoch 00028: loss improved from 0.01983 to 0.01950, saving model to unet.hdf5\n",
      "Epoch 29/35\n",
      " - 9172s - loss: 0.0192 - binary_accuracy: 0.9917 - val_loss: 0.0350 - val_binary_accuracy: 0.9870\n",
      "\n",
      "Epoch 00029: loss improved from 0.01950 to 0.01925, saving model to unet.hdf5\n",
      "Epoch 30/35\n",
      " - 10006s - loss: 0.0221 - binary_accuracy: 0.9906 - val_loss: 0.0335 - val_binary_accuracy: 0.9870\n",
      "\n",
      "Epoch 00030: loss did not improve\n",
      "Epoch 31/35\n",
      " - 9328s - loss: 0.0174 - binary_accuracy: 0.9925 - val_loss: 0.0358 - val_binary_accuracy: 0.9868\n",
      "\n",
      "Epoch 00031: loss improved from 0.01925 to 0.01743, saving model to unet.hdf5\n",
      "Epoch 32/35\n",
      " - 8244s - loss: 0.0177 - binary_accuracy: 0.9924 - val_loss: 0.0357 - val_binary_accuracy: 0.9869\n",
      "\n",
      "Epoch 00032: loss did not improve\n",
      "Epoch 33/35\n",
      " - 8187s - loss: 0.0176 - binary_accuracy: 0.9924 - val_loss: 0.0349 - val_binary_accuracy: 0.9871\n",
      "\n",
      "Epoch 00033: loss did not improve\n",
      "Epoch 34/35\n",
      " - 7988s - loss: 0.0174 - binary_accuracy: 0.9925 - val_loss: 0.0367 - val_binary_accuracy: 0.9868\n",
      "\n",
      "Epoch 00034: loss improved from 0.01743 to 0.01736, saving model to unet.hdf5\n",
      "Epoch 35/35\n",
      " - 8486s - loss: 0.0170 - binary_accuracy: 0.9927 - val_loss: 0.0362 - val_binary_accuracy: 0.9871\n",
      "\n",
      "Epoch 00035: loss improved from 0.01736 to 0.01699, saving model to unet.hdf5\n",
      "predict test data\n",
      "8/8 [==============================] - 21s 3s/step\n",
      "***** segmented_img before thresholding *****\n",
      "[[[[4.47219471e-04]\n",
      "   [1.78870414e-06]\n",
      "   [5.42610188e-08]\n",
      "   ...\n",
      "   [1.45699130e-06]\n",
      "   [1.42713950e-04]\n",
      "   [1.19837672e-02]]\n",
      "\n",
      "  [[1.19811975e-05]\n",
      "   [1.02596784e-08]\n",
      "   [4.58225020e-11]\n",
      "   ...\n",
      "   [5.98464851e-08]\n",
      "   [1.34290913e-05]\n",
      "   [2.17789784e-03]]\n",
      "\n",
      "  [[5.15856664e-06]\n",
      "   [2.45037568e-09]\n",
      "   [2.89559349e-12]\n",
      "   ...\n",
      "   [4.21822612e-08]\n",
      "   [7.72675412e-06]\n",
      "   [2.58307904e-03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.27993187e-03]\n",
      "   [2.68537388e-03]\n",
      "   [4.81895404e-04]\n",
      "   ...\n",
      "   [8.03356171e-01]\n",
      "   [8.99256110e-01]\n",
      "   [9.15423155e-01]]\n",
      "\n",
      "  [[4.59224731e-02]\n",
      "   [2.72664968e-02]\n",
      "   [1.03948014e-02]\n",
      "   ...\n",
      "   [2.04938337e-01]\n",
      "   [7.05587149e-01]\n",
      "   [8.74748945e-01]]\n",
      "\n",
      "  [[1.79043934e-01]\n",
      "   [1.92979679e-01]\n",
      "   [9.38051268e-02]\n",
      "   ...\n",
      "   [2.20152274e-01]\n",
      "   [6.43660784e-01]\n",
      "   [7.14411199e-01]]]\n",
      "\n",
      "\n",
      " [[[7.95812812e-03]\n",
      "   [3.17842845e-04]\n",
      "   [2.87100993e-05]\n",
      "   ...\n",
      "   [6.98799863e-02]\n",
      "   [2.98761316e-02]\n",
      "   [6.60581291e-02]]\n",
      "\n",
      "  [[7.44445599e-04]\n",
      "   [2.37305244e-06]\n",
      "   [1.44210688e-07]\n",
      "   ...\n",
      "   [1.44998312e-01]\n",
      "   [5.20318598e-02]\n",
      "   [3.91120762e-02]]\n",
      "\n",
      "  [[1.87133730e-04]\n",
      "   [1.31574339e-07]\n",
      "   [5.56668880e-08]\n",
      "   ...\n",
      "   [4.61738229e-01]\n",
      "   [2.91563213e-01]\n",
      "   [1.44991785e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.43661944e-05]\n",
      "   [7.19563218e-08]\n",
      "   [8.92058736e-12]\n",
      "   ...\n",
      "   [3.81816886e-02]\n",
      "   [1.22008123e-01]\n",
      "   [1.67621866e-01]]\n",
      "\n",
      "  [[2.99842097e-04]\n",
      "   [5.28073429e-07]\n",
      "   [6.32198294e-10]\n",
      "   ...\n",
      "   [1.98461130e-01]\n",
      "   [4.70920086e-01]\n",
      "   [5.81123173e-01]]\n",
      "\n",
      "  [[6.85447454e-03]\n",
      "   [7.41167314e-05]\n",
      "   [1.51658219e-06]\n",
      "   ...\n",
      "   [3.00879747e-01]\n",
      "   [6.25444233e-01]\n",
      "   [6.99458241e-01]]]\n",
      "\n",
      "\n",
      " [[[2.29761773e-03]\n",
      "   [2.15170367e-05]\n",
      "   [1.47152633e-07]\n",
      "   ...\n",
      "   [7.88861737e-02]\n",
      "   [2.80162901e-01]\n",
      "   [6.63106978e-01]]\n",
      "\n",
      "  [[3.54471340e-05]\n",
      "   [1.31631639e-08]\n",
      "   [8.40880837e-12]\n",
      "   ...\n",
      "   [3.29702616e-01]\n",
      "   [6.65571511e-01]\n",
      "   [9.05538917e-01]]\n",
      "\n",
      "  [[2.30758633e-06]\n",
      "   [3.07085503e-11]\n",
      "   [6.55116245e-15]\n",
      "   ...\n",
      "   [8.65679026e-01]\n",
      "   [9.50751305e-01]\n",
      "   [9.92642105e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[7.16896320e-05]\n",
      "   [8.90719605e-07]\n",
      "   [6.41974580e-08]\n",
      "   ...\n",
      "   [6.96502102e-04]\n",
      "   [1.46107795e-03]\n",
      "   [1.08683975e-02]]\n",
      "\n",
      "  [[2.32500560e-03]\n",
      "   [4.25500271e-04]\n",
      "   [1.34452843e-04]\n",
      "   ...\n",
      "   [1.45503534e-02]\n",
      "   [2.76051648e-02]\n",
      "   [8.25164467e-02]]\n",
      "\n",
      "  [[3.62178907e-02]\n",
      "   [1.42401727e-02]\n",
      "   [8.27982370e-03]\n",
      "   ...\n",
      "   [1.39569491e-01]\n",
      "   [1.77246407e-01]\n",
      "   [2.53534913e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[7.62040615e-02]\n",
      "   [2.54800394e-02]\n",
      "   [1.82648107e-01]\n",
      "   ...\n",
      "   [1.13069871e-02]\n",
      "   [1.59331132e-02]\n",
      "   [5.07137068e-02]]\n",
      "\n",
      "  [[6.72594234e-02]\n",
      "   [8.71293247e-02]\n",
      "   [3.49125385e-01]\n",
      "   ...\n",
      "   [1.29100319e-03]\n",
      "   [3.91748920e-03]\n",
      "   [1.44597599e-02]]\n",
      "\n",
      "  [[4.16441038e-02]\n",
      "   [8.99094045e-02]\n",
      "   [3.21536183e-01]\n",
      "   ...\n",
      "   [7.54537992e-04]\n",
      "   [3.67610133e-03]\n",
      "   [2.00492367e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.97398531e-01]\n",
      "   [6.97525799e-01]\n",
      "   [2.59210199e-01]\n",
      "   ...\n",
      "   [6.07561844e-07]\n",
      "   [2.95950122e-06]\n",
      "   [3.18750797e-04]]\n",
      "\n",
      "  [[9.94433582e-01]\n",
      "   [9.93161201e-01]\n",
      "   [9.22676980e-01]\n",
      "   ...\n",
      "   [3.72266586e-05]\n",
      "   [5.47923628e-05]\n",
      "   [1.69721071e-03]]\n",
      "\n",
      "  [[9.88369107e-01]\n",
      "   [9.97172058e-01]\n",
      "   [9.61914599e-01]\n",
      "   ...\n",
      "   [3.51053709e-03]\n",
      "   [2.63829180e-03]\n",
      "   [1.39993671e-02]]]\n",
      "\n",
      "\n",
      " [[[9.95542347e-01]\n",
      "   [9.95876312e-01]\n",
      "   [9.78155315e-01]\n",
      "   ...\n",
      "   [9.98792529e-01]\n",
      "   [9.97463584e-01]\n",
      "   [9.82915163e-01]]\n",
      "\n",
      "  [[9.98933971e-01]\n",
      "   [9.97682095e-01]\n",
      "   [9.26812410e-01]\n",
      "   ...\n",
      "   [9.99728382e-01]\n",
      "   [9.99540091e-01]\n",
      "   [9.98062313e-01]]\n",
      "\n",
      "  [[9.93166029e-01]\n",
      "   [9.82492208e-01]\n",
      "   [7.62558460e-01]\n",
      "   ...\n",
      "   [9.99615312e-01]\n",
      "   [9.99854803e-01]\n",
      "   [9.99377668e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.24089670e-01]\n",
      "   [9.99907374e-01]\n",
      "   [9.99999642e-01]\n",
      "   ...\n",
      "   [9.99267995e-01]\n",
      "   [9.99767244e-01]\n",
      "   [9.99337494e-01]]\n",
      "\n",
      "  [[9.64756370e-01]\n",
      "   [9.99954581e-01]\n",
      "   [9.99999642e-01]\n",
      "   ...\n",
      "   [9.99866009e-01]\n",
      "   [9.99886751e-01]\n",
      "   [9.99520063e-01]]\n",
      "\n",
      "  [[9.54225421e-01]\n",
      "   [9.99644876e-01]\n",
      "   [9.99986887e-01]\n",
      "   ...\n",
      "   [9.99478996e-01]\n",
      "   [9.98782337e-01]\n",
      "   [9.93741214e-01]]]\n",
      "\n",
      "\n",
      " [[[6.13915682e-01]\n",
      "   [3.80693465e-01]\n",
      "   [1.29058987e-01]\n",
      "   ...\n",
      "   [9.99589145e-01]\n",
      "   [9.96822596e-01]\n",
      "   [9.64845717e-01]]\n",
      "\n",
      "  [[3.82615656e-01]\n",
      "   [2.91401863e-01]\n",
      "   [4.40085493e-02]\n",
      "   ...\n",
      "   [9.99490023e-01]\n",
      "   [9.97560024e-01]\n",
      "   [9.84268427e-01]]\n",
      "\n",
      "  [[2.42127642e-01]\n",
      "   [1.10358000e-01]\n",
      "   [5.24645578e-03]\n",
      "   ...\n",
      "   [9.98765588e-01]\n",
      "   [9.97280717e-01]\n",
      "   [9.90569830e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.07303667e-01]\n",
      "   [1.40075702e-02]\n",
      "   [1.22636801e-03]\n",
      "   ...\n",
      "   [7.27580698e-07]\n",
      "   [3.46315164e-06]\n",
      "   [1.62696684e-04]]\n",
      "\n",
      "  [[4.41094756e-01]\n",
      "   [2.83610914e-02]\n",
      "   [2.50459579e-03]\n",
      "   ...\n",
      "   [4.75101388e-06]\n",
      "   [3.33648313e-05]\n",
      "   [1.21297943e-03]]\n",
      "\n",
      "  [[4.60220337e-01]\n",
      "   [9.39319432e-02]\n",
      "   [1.13572264e-02]\n",
      "   ...\n",
      "   [1.92045962e-04]\n",
      "   [9.59943107e-04]\n",
      "   [1.10590002e-02]]]]\n",
      "------------------------------------------------------------\n",
      "***** segmented_img after thresholding *****\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "dict_keys(['loss', 'val_loss', 'binary_accuracy', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbae6d3cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbae736a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to image\n"
     ]
    }
   ],
   "source": [
    "#Defining the U-Net model\n",
    "\n",
    "#class myUnet(object):\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "smooth = 1\n",
    "\n",
    "\n",
    "'''def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return (1-dice_coef(y_true, y_pred))'''\n",
    "        \n",
    "def get_unet():\n",
    "\n",
    "        #inputs = Input((self.img_rows, self.img_cols,3))\n",
    "        inputs = Input((img_rows, img_cols, 1))\n",
    "        \n",
    "        conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print(\"conv1 shape:\",conv1.shape)\n",
    "        conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        #print( \"conv1 shape:\",conv1.shape)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print(\"pool1 shape:\",pool1.shape)\n",
    "        \n",
    "        conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print( \"conv2 shape:\",conv2.shape)\n",
    "        conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "       # print( \"conv2 shape:\",conv2.shape)\n",
    "        #drop2 = Dropout(0.5)(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print( \"pool2 shape:\",pool2.shape)\n",
    "        \n",
    "        conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print(\"conv3 shape:\",conv3.shape)\n",
    "        conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        #print(\"conv3 shape:\",conv3.shape)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        #print(\"pool3 shape:\",pool3.shape)\n",
    "        #drop3 = Dropout(0.5)(conv3)\n",
    "        \n",
    "        conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        print(\"conv3 shape:\",conv3.shape)\n",
    "        conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        #pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        \n",
    "        up5 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv4))\n",
    "        merge5 = merge([conv3,up5], mode = 'concat', concat_axis = 3)\n",
    "        conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
    "        #drop4 = Dropout(0.1)(conv4)\n",
    "        conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        \n",
    "        up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "        merge6 = merge([conv2,up6], mode = 'concat', concat_axis = 3)\n",
    "        conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        #drop5 = Dropout(0.1)(conv5)\n",
    "        conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "        \n",
    "        up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = merge([conv1,up7], mode = 'concat', concat_axis = 3)\n",
    "        conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        #drop5 = Dropout(0.1)(conv5)\n",
    "        conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "      \n",
    "        conv8 = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "        \n",
    "        model = Model(input = inputs, output = conv8)\n",
    "\n",
    "        #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "                \n",
    "        optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.00000001, decay=0.0)\n",
    "        #model.compile(optimizer = optimizer, loss = dice_coef_loss, metrics=[dice_coef])\n",
    "        model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "'''def resize_arr(imgs):\n",
    "        imgsp = np.ndarray((1,imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            imgsp[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "        #imgsp = imgsp[..., np.newaxis]\n",
    "        imgsp = np.expand_dims(imgsp, axis=1)\n",
    "        return imgsp'''\n",
    "    \n",
    "def resize_arr(imgs):\n",
    "        imgsp = imgs.reshape((imgs.shape[0], img_cols, img_rows, 1))\n",
    "        return imgsp\n",
    "    \n",
    "def train():\n",
    "\n",
    "        #print(\"loading data\")\n",
    "        #imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        #print(\"loading data done\")\n",
    "        Train_data_image2 = resize_arr(Train_data_image)\n",
    "        Train_data_mask2 = resize_arr(Train_data_mask)\n",
    "        \n",
    "        Train_data_image2 = Train_data_image2.astype('float32')\n",
    "        mean = np.mean(Train_data_image2)  # mean for data centering\n",
    "        std = np.std(Train_data_image2)  # std for data normalization\n",
    "\n",
    "        Train_data_image2 -= mean\n",
    "        Train_data_image2 /= std\n",
    "        print(\"******* Train_data_image2 ********\")\n",
    "        print(Train_data_image2)\n",
    "        print(Train_data_image2.shape)\n",
    "\n",
    "        Train_data_mask2  = Train_data_mask2.astype('float32')\n",
    "        Train_data_mask2  /= 255. # scale masks to [0, 1]\n",
    "        print(\"******* Train_data_mask2 ********\")\n",
    "        print(Train_data_mask2)\n",
    "        print(Train_data_mask2.shape)\n",
    "        \n",
    "        #np.reshape(a, (2, 3)) \n",
    "        #np.reshape(Train_data_image[0][0], (512, 512, 3)) \n",
    "            \n",
    "        model = get_unet()\n",
    "        print(\"got unet\")\n",
    "        model.summary()\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "        print('Fitting model...')\n",
    "        history = model.fit(Train_data_image2, Train_data_mask2, batch_size=1, nb_epoch=35, verbose=2, validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "        \n",
    "        #model.load_weights('unet.hdf5')\n",
    "        \n",
    "        Test_data_image2 = resize_arr(Test_data_image)\n",
    "            \n",
    "        Test_data_image2 =  Test_data_image2.astype('float32')\n",
    "        Test_data_image2 -= mean\n",
    "        Test_data_image2 /= std \n",
    "        \n",
    "        #Test_data_mask2 = resize_arr(Test_data_mask)\n",
    "            \n",
    "        #Test_data_mask2  = Test_data_mask2.astype('float32')\n",
    "        #Test_data_mask2  /= 255.\n",
    "        \n",
    "        print('predict test data')\n",
    "        Test_data_mask_predict = model.predict(Test_data_image2, batch_size=1, verbose=1)\n",
    "        #print(Test_data_mask_predict)\n",
    "        #Test_data_mask_predict[Test_data_mask_predict>0.5]=1\n",
    "        #Test_data_mask_predict[Test_data_mask_predict<=0.5]=0\n",
    "        #print(Test_data_mask_predict)\n",
    "        np.save('/home/hp/data/Test_data_mask_predict.npy', Test_data_mask_predict)\n",
    "        segmented_img = np.load('/home/hp/data/Test_data_mask_predict.npy')\n",
    "        print(\"***** segmented_img before thresholding *****\")\n",
    "        print(segmented_img)\n",
    "        print('-'*60)\n",
    "        segmented_img[segmented_img>0.5] = 1\n",
    "        segmented_img[segmented_img<=0.5] = 0\n",
    "        print(\"***** segmented_img after thresholding *****\")\n",
    "        print(segmented_img)\n",
    "        np.save('/home/hp/data/segmented_img.npy', segmented_img)\n",
    "       \n",
    "        # list all data in history\n",
    "        print(history.history.keys())\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['binary_accuracy'])\n",
    "        plt.plot(history.history['val_binary_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show() \n",
    "        \n",
    "        \n",
    "        # summarize history for accuracy\n",
    "        '''plt.plot(history.history['dice_coef'])\n",
    "        plt.plot(history.history['val_dice_coef'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('segmentation accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show() ''' \n",
    "        \n",
    "def save_img():\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load('/home/hp/data/segmented_img.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"/home/hp/data/Result/%d.png\"%(i+1))\n",
    "            \n",
    "#if __name__ == '__main__':\n",
    "#myunet = myUnet()\n",
    "#Train_data_image = myunet.resizei(Train_data_image)\n",
    "#Train_data_mask = myunet.resizei(Train_data_mask)\n",
    "#Test_data_image = myunet.resizei(Test_data_image)\n",
    "\n",
    "train()\n",
    "save_img()            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ... False  True  True]\n",
      " [False False False ... False  True  True]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False  True]\n",
      " [False False False ... False  True  True]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ...  True  True False]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False  True]\n",
      " [False False False ... False  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[1. 1. 0. ... 1. 1. 1.]\n",
      " [1. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "[[ True  True False ...  True  True  True]\n",
      " [ True False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [ True  True False ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " [0. 1. 1. ... 1. 1. 1.]\n",
      " [0. 1. 1. ... 1. 1. 1.]]\n",
      "[[False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False  True  True ...  True  True  True]\n",
      " [False  True  True ...  True  True  True]\n",
      " [False  True  True ...  True  True  True]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "printing segmented_img\n",
      "[[1. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ True False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "--------------------------------------------------------------------------------\n",
      "printing test labels\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0.866974   0.80075256 0.77516643 0.82509755 0.80043036 0.73734305\n",
      " 0.78873671 0.72605565]\n",
      "0.7900695389088697\n"
     ]
    }
   ],
   "source": [
    "def dice_coef(seg, gt):\n",
    "    if seg.shape != gt.shape:\n",
    "        raise ValueError(\"Shape mismatch: seg and gt must have to be of the same shape.\")\n",
    "    else:\n",
    "        intersection = np.logical_and(seg, gt)\n",
    "        value = (2. * intersection.sum())  / (seg.sum() + gt.sum())\n",
    "    return value\n",
    "\n",
    "path = '/home/hp/data/Result/'\n",
    "path2 = '/home/hp/data/Test/label1/'\n",
    "list = os.listdir('/home/hp/data/Test/label1/') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for j in range(1,size+1): \n",
    "    seg=mpimg.imread(path+str(j)+'.png')\n",
    "    print(\"printing segmented_img\")\n",
    "    print(seg)\n",
    "    seg = np.asarray(seg).astype(np.bool)\n",
    "    print(seg)\n",
    "    print('-'*80)\n",
    "    print(\"printing test labels\")\n",
    "    gt=mpimg.imread(path2+str(j)+'.png')\n",
    "    print(gt)\n",
    "    gt = np.asarray(gt).astype(np.bool)\n",
    "    print(gt)\n",
    "    print('%'*80)\n",
    "    value = dice_coef(seg, gt)\n",
    "    accuracy.append(value)  \n",
    "    \n",
    "#print(accuracy)\n",
    "accu = np.array(accuracy) \n",
    "print(accu)\n",
    "print(accu.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#converting jpg to png\n",
    "\n",
    "path = '/home/hp/data/Result/'\n",
    "list = os.listdir('/home/hp/data/Result/') # dir is your directory path\n",
    "size = len(list)\n",
    "print (size)\n",
    "\n",
    "for j in range(1,size+1): \n",
    "   im = Image.open(path+str(j)+'.jpg')\n",
    "   im.save(path+str(j)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
